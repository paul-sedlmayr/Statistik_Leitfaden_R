---
title: "Statistik Leitfaden R"
authors: "Paul Sedlmayr, Maximilian Gerschütz"
date: "`r Sys.Date()`"
format:
  html:
    toc: true  # Enable table of contents
    #css: toc-styles.css
    #toc-depth: 6  # Adjust depth (optional)
    toc-location: left  # Set ToC position (left, right)
    toc-title: Überblick
    header-includes: |
      <img src="logo.png" style="position:absolute; top:10px; right:10px; height:50px;">
    theme: pulse
page-layout: article
#bibliography: references.bib
#csl: chicago-fullnote-bibliography
execute:
  cache: false
tbl-cap-location: top
---

```{r, echo=FALSE}
knitr::opts_chunk$set(tidy = TRUE, fig.width = 5, fig.height = 3, dev = "png",
                      cache = TRUE, echo = TRUE, message = FALSE, warning = FALSE)
```

::: callout-tip
### Vorwort

Dieser Leitfaden für statistische Datenanalyse in R soll als ergänzende Ressource zur Lehre an der Universität Graz dienen. Er richtet sich speziell an Studierende, die R für Bachelor- oder Masterarbeiten verwenden wollen, oder sich einfach mit den Grundlagen und Anwendungen statistischer Methoden in R vertraut machen möchten.

Ziel ist es, eine kompakte und verständliche Anleitung bereitzustellen, die das eigenständige Arbeiten mit R erleichtert. Ich erhebe keinen Anspruch auf absolute Richtigkeit oder Vollständigkeit der Inhalte. Der Leitfaden wird regelmäßig aktualisiert. Falls Ihnen Fehler auffallen oder Sie Verbesserungsvorschläge haben, freuen wir uns über eine Rückmeldung per E-Mail (`paul.sedlmayr@uni-graz.at`, `maximilian.gerschuetz@uni-graz.at`).
:::

::: callout-warning
### Diese Seite ist noch nicht fertig gestellt und wird laufend aktualisiert.

Wir freuen uns über Feedback & Anmerkungen!
:::

# Einführung

#### Installation & Laden von Packages

Im ersten Schritt installieren und laden wir Packages. Diese enthalten Funktionen, welche wir später nutzen werden. Wenn man ein Package, zum Beispiel das Package / die Library tidyverse, zum ersten Mal verwendet, muss man es mit der Funktion `install.packages("tidyverse")` installieren. Anschließend kann man es mit der Funktion `library(tidyverse)` laden. Bei `install.packages()` brauchen wir Anführungszeichen "", bei bereits heruntergeladenen Packages (`library()`) nicht.

Um die Packages im folgenden Code zu installieren, entferne das `#` um den Kommentar `#install.packages("tidyverse")` zu einer Zeile Code zu verwandeln.

```{r install packages, message=FALSE}

# Dies ist ein Kommentar

# Packages installieren
#install.packages("tidyverse")

# Diese Funktion müssen wir für alle noch nicht heruntergeladenen Packages anwenden. Weitere Packages im Skript:
# "rempsyc", "haven", "car", "effectsize" ,"psych", "GGally", "afex", "emmeans", "boot"

# Packages laden
library(tidyverse) # All-around package
library(rempsyc) # Convenience-functions für Psychologie
library(haven) # SPSS-Files (.sav) einlesen
library(readxl) # Excel-Files (.xlsx) einlesen
library(car) # Anova
library(afex) # Anova
library(emmeans) # Post-hoc Tests
library(effectsize) # Effektstärkten
library(psych) # All-around package für Statistik
library(GGally) # Korrelationsmatrix
library(lm.beta) # Standardiertes Regressionsgewicht
library(flextable) # Tabelle in Word konvertieren
library(broom) # Für schöne lm-Tabelle
library(boot) # Bootstrapping
library(pwr) # Power Analyse
```

::: callout-warning
Um Teile aus dem folgenden Code zu nutzen, müssen die jeweiligen Packages heruntergeladen und geladen werden!
:::

#### Wie funktionieren Funktionen

Die meisten Funktionen in R sind gut dokumentiert. Für eine `funktion()` können in R mit dem Kommando `?funktion` die Dokumentation zur jeweiligen Funtion aufrufen. Alternativ kann man (rechts) unter "Help" eine Funktion suchen. Es ist lediglich zu beachten, dass eine Funktion aus einem externen Package (s. oben) zu erst über das Package geladen werden muss, um die Dokumentation einsehen zu können. Wenn wir die folgende Zeilen auskommentieren, können wir die Dokumention zur jeweiligen Funktion einsehen.

```{r}
#?library
```

#### Grundlegende Operatoren

Mit dem assignment operator `<-` kann man Variablen erstellen. Den Inhalt der Variable kann man ganz einfach einsehen, indem man den Namen der Variable in der Konsole / im Skript ausführt. Alternativ kann man die Funktion `print()` am jeweiligen Objekt verwenden. Die Funktion `c()` wird verwendet wenn wir einzelne Objekte zu einem Vektor zusammenfassen. Das ist besonders hilfreich, wenn wir z. B. gezielt mehrere Zeilen oder Spalten eines Dataframes auswählen wollen: `df[c("Reihe_1", "Reihe_2"), c("Spalte_1", "Spalte_2")]`.

```{r basic operators}
# Dies ist ein Kommentar
x <- 10 # oder x = 10
x

text_y <- "Hello"
text_z <- "WORLD"

# Print: um ein Objekt zu "drucken"
print(text_y)

text_y_z <- c(text_y, text_z)
text_y_z
```

Der "Pipe-Operator" `%>%` aus dem `tidyverse`-Package wird verwendet, um eine Funktion an einem Objekt anzuwenden, ohne das Objekt in der Funktion stehen zu haben. In der herkömmlichen Variante ist es ein Objekt in den Klammern: "`f(X)`". Hier liest sich "`X %>% f()`" wie "nimm `X` und mache `f()` damit. Obwohl das nichts am Output verändert, nutzen wir `%>%`, um eine Struktur im Code zu behalten. Dies ist speziell dann wichtig, wenn man mehrere Funktionen nacheinander anwendet.

Wenn wir beispielsweise eine Tabelle von Autos `mtcars` 1. nach der Variable `mpg` (miles per gallon) filtern wollen, 2. bestimmte Variablen auswählen wollen und 3. die Autos dann nach der Leistung (`hp`) ordnen wollen, brauchen wir nicht zwangsläufig 3 Zeilen Code dafür. Beide Herangehensweisen kommen zum selben Ergebnis

```{r}
# 1. Normal
cars_filtered <- filter(mtcars, mpg > 20)
cars_selected <- select(cars_filtered, mpg, cyl, hp)
cars_final <- arrange(cars_selected, desc(hp))

# 2. Mit Pipe %>%
cars_final <- mtcars %>% filter(mpg > 20) %>% select(mpg, cyl, hp) %>% arrange(desc(hp))

# Die ersten 3 Reihen anzeigen
head(cars_final, 3)
```

#### Mathematische Operatoren

Man kann einfache Berechnungen mit Zahlen oder Vektoren durchführen. Mit eckigen Klammern kann man Positionen in einem Vektor auswählen / einsehen.

```{r}
x^2

# Vector erstellen
vec_1 <- c(5, 10, 15)

vec_1

vec_1[1]
vec_1[2]
vec_1[3]

vec_1 * 2
```

| Operation      | Zeichen |
|----------------|---------|
| Addition       | \+      |
| Multiplikation | \*      |
| Division       | /       |
| Potenz         | \^      |

### Files einlesen

::: callout-note
#### Was ist ein Dataframe "df"?
In R nutzen wir typischerweise Dataframes. Das ist ein anderer Name für eine Tabelle, wie man sie aus Microsoft Excel kennt. Meistens nutzt man daher die Abkürzung `df` für einen Dataframe.
::: 

Um ein File einzulesen, müssen wir den Pfad des Files angeben. Befinden sich das Skript und File im selben Ordner, genügt für das csv-File "`data_1.csv`" der Pfad `".//data_1.csv"`. Um den Pfad zum File nicht händisch schreiben zu müssen, eignet es sich, mit einem Rechtsklick und "Pfad kopieren" den Link zu kopieren. Bei Problemen kann man im Fenster "Environment" (normalerweise rechts oben) auf "Import Dataset" gehen und ein File manuell einlesen.

```{r file einlesen, message=FALSE}
df <- read_csv('data_1.csv') 
```

Um SPSS Files mit dem Typ `.sav` einzulesen, kann man folgende Funktion aus dem `haven`-Package verwenden:

```{r SPSS files einlesen, message=FALSE}
df_sav <- read_sav(".//data_2.sav")
```

Um Excel Files mit dem Typ `.xlsx` einzulesen, kann man folgende Funktion aus dem `readxl`-Package verwenden:

```{r XLSX files einlesen, message=FALSE}
df_xlsx <- read_xlsx(".//data_2.xlsx")
```

#### Überblick verschaffen

Um sich einen Überblick über ein Datenfile zu verschaffen, eignen sich die folgenden Funktionen.

```{r}
# Ersten fünf Zeilen
head(df, 5)
```

Welche Spalten ("Columns") sind in meinem Dataframe?

```{r}
colnames(df)
```

Hinweis: `$` wird verwendet, um eine Spalte auszuwählen.
```{r}
summary(df$IQ)
```

Einfache Übersicht über Ausprägungen der Variable:
```{r}
table(df$bedingung)
```

## Variablen Transformation

### Variablen umbennen / umkodieren

```{r variable transformation}
# Variable umbenennen nach dem Schema: "neu" = alt
df <- df %>% rename("WMS4_delayed_recall" = wmsva14)

# Variable transformieren: zu einem Faktor, d.h. Nominalskalenniveau
df$Bildungsstand <- df$Bildungsstand %>% as_factor()

# Keine Angabe in Variable "Rauchen" wird zu NA
df$Rauchen[df$Rauchen == "Keine Angabe"] <- NA
```

Oft wollen wir nominal skalierte Variablen zu Dummy-Variablen umkodieren. Beispielsweise wollen wir die Zugehörigkeit zur Kontroll- oder Experimentalbedingung numerisch zu 1 und 0 kodieren. Die Dummy-Variable erhält das Label `experimentalgruppe` mit den Ausprägungen 1 (ja $\rightarrow$ gehört zur Experimentalgruppe) und 0 (nein $\rightarrow$ gehört nicht zur Experimentalgruppe). Am besten wählt man ein informatives Label, also eines, welches den Namen der Referenzgruppe beinhaltet. Wenn wir die Variable nur `gruppe` nennen würden, wäre es nicht klar, welcher Wert zu welcher Gruppe gehört. ==check dummy coding==

```{r}
# Rekodieren zu Dummy Variable
df$experimentalgruppe <- ifelse(
  df$bedingung == "Experimental", 1,
  ifelse(df$bedingung == "Kontroll", 0, NA_real_)
)
```

### Filtern

Eine einfache Art und Weise zu filtern, ist `filter()` aus dem `dplyr`-Package (Teil der `tidyverse`-Library). Wir schreiben `=` doppelt (`==`), da es sich um einen Vergleich handelt. Ein einfaches `=` wird verwendet wie der Assignmeent Operator `<-`. Daher bedeutet `=` in R meistens, dass man ein Objekt überschreiben will.

Wenn wir nur Zeilen mit einem bestimmten Wert in einer Zelle filtern wollen:
```{r}
df_experimental <- df %>% filter(bedingung == "Experimental") 
```

Wenn wir Zeilen mit fehlenden Werten "`NA`" in einer einer Variable enfernen wollen, nutzen wir die `is.na()`-Funktion um `NA`-Werte zu erkennen. Das `!` ist eine Negation: wir wollen die Werte, die **nicht** `NA` sind.

```{r}
df_filtered <- df %>% filter(!is.na(bedingung)) 
```



### z-Standardisierung & Zentrierung

`mutate()` wird häufig verwendet, um Variablen zu transformieren. Um eine z-standardisierte Variable (hier: `BDI_z`) aus der herkömmlichen Variable (hier: `BDI`) zu erstellen, subtrahieren wir den Wert vom Mittelwert ("zentrieren") und teilen ihn durch die Standardabweichung ($z_i = \frac{x_i - \bar x}{s}$). Alternativ können wir auch die Funktion `scale()` verwenden.

```{r}
df <- df %>% mutate(BDI_z2 = ((BDI - mean(BDI)) / sd(BDI)))
```

In der Regression kann es sinnvoll sein, Werte zu zentrieren, um die Ergebnisse besser interpretieren zu können. Zentrieren bedeutet, wir verschieben die Punkte im Koordinatensystem. Das wird typischerweise am Mittelwert durchgeführt ($x_{c,i}=x_i - \bar x$).

```{r}
df$BDI_c <- df$BDI - mean(df$BDI)
```

### Aus einzelnen Participant-Files ein Gesamt-File erstellen

Wenn wir mit einem Programm wie *PsychoPy* arbeiten, wird für jeden Participant häufig eine separate Excel-Datei erzeugt. Eine zusammengeführter Dataframe liegt jedoch noch nicht vor und muss erst noch von uns erstellt werden. Wir gehen davon aus, dass sich alle `.xlsx`-Dateien im Ordner `data` befinden.

::: callout-warning
Dieser Ordner muss im gleichen Verzeichnis liegen wie das aktuelle R-Skript. Nur dann funktioniert der relative Pfad `./data` korrekt. Ein häufiger Fehler entsteht durch falsch gesetzte Pfade – zur Kontrolle kann man per Rechtsklick auf den `data`-Ordner den vollständigen Pfad kopieren (siehe auskommentiertes Beispiel unten).
:::

Der zentrale Trick: Wir nutzen `lapply()` und `do.call(rbind, ...)`, um die Daten aus allen Dateien zeilenweise zu einem Dataframe zusammenzufügen.

```{r}
# Ordnerpfad zu den Daten definieren
folder_data <- "./data"  # Pfad anpassen!

# Prüfen, ob der Datenordner existiert
if (!dir.exists(folder_data)) {
  stop("Datenordner nicht gefunden: ", folder_data)
}

# Liste aller Excel-Dateien im Ordner erstellen
file_list <- list.files(path = folder_data, pattern = "\\.xlsx$", full.names = TRUE)

# Alle Dateien einlesen und in eine Liste speichern
data_list <- lapply(file_list, readxl::read_excel)

# Alle Participants zu einem gemeinsamen Dataframe kombinieren
df_combined <- do.call(rbind, data_list)
```

### Mittelwerte pro Participant bilden

Wenn wir über einen Datensatz verfügen, in dem alle Trials aller Participants enthalten sind, müssen wir häufig noch Summen- oder Mittelwerte pro Participant und pro Bedingung berechnen. Im folgenden Beispiel berechnen wir den Mittelwert, die Standardabweichung und die Summe der korrekten Antworten (`key_resp_Trial.corr`) pro Participant (`Code`) und pro Bedingung (`SubTopic_Nr`).

Hinweis: wie an den ersten Zeilen zu sehen ist, sind unsere Daten noch im long format. Das bedeutet, pro Participant gibt es so viele Zeilen wie die Bedingung (`SubTopic_Nr`) Levels hat. Für die Arbeit mit R ist dieses long Format oft nützlich, für SPSS benötigen wir i.d.R. das wide Format, also alle Werte eines Participants sind in einer Zeile. Das bedeutet, die Spalte der AV (hier z.B. `mean_pro_bedingung`) müsste auf mehrere Spalten aufgeteilt werden (z.B. `mean_bedingung_1`, `mean_bedingung_2`, ...).

```{r}
df_summary <- df_combined %>%
  group_by(Code, SubTopic_Nr) %>%
  summarise(mean_pro_bedingung = mean(key_resp_Trial.corr),
            sd_pro_bedingung = sd(key_resp_Trial.corr),
            sum_pro_bedingung = sum(key_resp_Trial.corr)) %>%
  ungroup()

head(df_summary, 3)
```

### Wide Format vs. Long Format

```{r, include=FALSE}
df_2 <- read_csv('.//data_2.csv')
# Daten ins long-Format bringen: neue Spalte "time" mit Zeitpunkt sowie "wellbeing" mit Zellenwerten der alten Spalten
colnames(df_2) <- as.character(colnames(df_2))

df_2_long <- pivot_longer(data = df_2, cols = c("wellbeing_t0", "wellbeing_t1", "wellbeing_t2"), names_to = "time", values_to = "wellbeing")

df_2_wide <- pivot_wider(data = df_2_long, names_from = "time", values_from = "wellbeing", id_cols = c("participant_id", "therapy", "therapy_group", "gender"))
```


```{r, echo = FALSE}
#| label: tbl-longwide
#| tbl-cap: "Vergleich: Wide Format (oben) vs. Long Format (unten)"


knitr::kable(head(df_2_wide[, c(1, 2, 4, 5, 6, 7)], 5))
knitr::kable(head(df_2_long[, -3], 5))
```


Das wide und long Format sind die häufigsten Strukturen von Datensätzen. Am besten erkennt man sie an den folgenden Kennzeichen: 1. Im **wide Format** hat jede Person **eine Zeile** 2. Im **long Format** hat jede Person **mehrere Zeilen**

Andere Statistikprogramme wie SPSS verwenden oft das wide Format. Im Folgenden lesen wir einen Datensatz ein. Dieser enthält die well-being Werte von Personen mit oder ohne Therapie zu drei Zeitpunkten. Der Datensatz ist im wide Format. Wir haben eine Zeile pro Person und drei Spalten für den Zeitpunkt.

```{r}
df_2 <- read_csv('.//data_2.csv')
head(df_2)
```

Die Funktionen `pivot_longer()` und `pivot_wider()` aus dem `tidyverse` sind hierfür hilfreich. Wir konvertieren den Datensatz ins long Format, wo eine Person anschließend eine Zeile pro Zeitpunkt, also insgesamt drei, hat. Wir wollen die Werte aus den drei Spalten in einer Spalte vereinen (`values_to = "wellbeing"`). Dafür wählen wir die Spalten aus, welche die Werte enthalten (`cols = c()`). Zusätzlich erstellen wir eine neue Spalte, welche den Zeitpunkt kodiert (`names_to = "time"`).

```{r}
# Daten ins long-Format bringen: neue Spalte "time" mit Zeitpunkt sowie "wellbeing" mit Zellenwerten der alten Spalten
colnames(df_2) <- as.character(colnames(df_2))

df_2_long <- pivot_longer(data = df_2, cols = c("wellbeing_t0", "wellbeing_t1", "wellbeing_t2"), names_to = "time", values_to = "wellbeing")

head(df_2_long)
```

Wenn wir die Daten nun zurück ins wide Format bringen wollen, geben wir die Spalte an, welche die unterschiedlichen Zeitpunkte kodiert (`names_from = time`). Zudem müssen wir die Spalte angeben, welche jene Werte enthält, die wir jetzt wieder auf drei Spalten aufteilen wollen (`values_from = "wellbeing"`). Wir können zusätzlich angeben, wie zusammen gehörende Werte identifiziert werden sollen, bzw.. welche Spalten unverändert bleiben sollen (`id_cols = c("participant_id", "therapy", "therapy_group", "gender")`). Wir sehen, dass diese Operation uns den Datensatz im ursprünglichen Zustand zurück gibt.

```{r}
df_2_wide <- pivot_wider(data = df_2_long, names_from = "time", values_from = "wellbeing", id_cols = c("participant_id", "therapy", "therapy_group", "gender"))

head(df_2_wide)
```


# Deskriptive Statistik

Wir können ganz einfach den Mittelwert und die Standardabweichung von einer Spalte berechnen.

```{r}
mean(df$Gewissenhaftigkeit)
sd(df$Gewissenhaftigkeit)
```

Um uns deskriptive Statistiken pro Gruppe ausgeben zu lassen, müssen wir `group_by()` verwenden.

```{r}
descriptives <- df %>% 
  group_by(bedingung) %>%
  summarize(
    M = mean(Gewissenhaftigkeit),
    SD = sd(Gewissenhaftigkeit),
    n = n(),
  )

descriptives
```

Zudem bietet das `psych`-Package eine praktische Funktion:

```{r}
describe(df$Extraversion)
```

# Statistische Verfahren

::: callout-important
#### Die Funktionen statistischer Verfahren sind meistens folgendermaßen aufgebaut:

**1.  Formelbasiert :**

`verfahren(Abhängige_Variable ~ Unabhängige_Variable_1 + Unabhängige_Variable_2, data = Datensatz_df)`.

**2.  Nicht-formelbasiert (direkte Übergabe von Variablen):**

`verfahren(df$Variable_A, df$Variable_B)`.

**3. Ausnahme** - Die Funktionen zur ANOVA aus dem `afex()`-Package:

`aov_ez(id = "ProbandInnen-Code", dv = "Abhängige_Variable", between = ("Between_UV1", "Between_UV2"), within = ("Within_UV1", "Within_UV2"), data = Datensatz_df)` 
:::

# t-Test

### t-Test über einen Mittelwert:

$H_0: \mu = 100$

```{r}
t.test(df$IQ, mu = 100)
```

### t-Test über zwei unabhängige Stichproben:

Mit `var.equal` können wir angeben, ob Varianzhomogenität vorliegt. Wenn die Varianzen nicht homogen sind, verwenden wir den Welch's t-Test, eine Version des t-Tests bei dem der Standardfehler nicht mit der gepoolten Varianz berechnet wird und die Freiheitsgrade (df) korrigiert sind: S. `df = 90.395` ist keine ganze Zahl. Der Welch's t-Test ist die Default-Einstellung bei `t.test()` für zwei unabhängige Stichproben, da dieser robuster gegenüber unterschiedlich großen Gruppengrößen und Varianzen ist.

$H_0: \mu_1 = \mu_2$

```{r}
t.test(correct_items ~ bedingung, data = df, var.equal = FALSE)
```

### t-Test über zwei abhängige Stichproben:

$H_0:$ Das well-being hat sich durch die Intervention nicht verändert.

```{r}
t.test(df_2$wellbeing_t0 , df_2$wellbeing_t1, paired = TRUE)
```

### Effektgröße Cohen's $d$

| Cohen’s $d$ | Interpretation   |
|-------------|------------------|
| ≈ 0.20      | Kleiner Effekt   |
| ≈ 0.50      | Mittlerer Effekt |
| ≈ 0.80      | Großer Effekt    |

: Interpretation von Cohen’s $d$ nach Konventionen (Cohen, 1988) {#tbl-cohen_d}

Für die Berechnung können wir die Funktion `cohens_d()` aus dem Package `effectsize()` verwenden.

```{r}
#t.test(correct_items ~ bedingung, data = df, var.equal = FALSE)
cohens_d(correct_items ~ bedingung, data = df, var.equal = FALSE)
```

### Voraussetzungen t-Test

::: callout-tip
## Statistische Voraussetzungen

Beim Testen der Voraussetzungen können wir entweder deskriptivstatistische oder inferenzstatistische Verfahren verwenden. Deskriptivstatistisch kann man die Verfahren mit Plots untersuchen (z.B. Residual Plots, QQ Plots). Inferenzstatistiche Verfahren werden mit Tests durchgeführt (z.B. Kolmogorov-Smirnov Test). Beide Herangehensweisen haben ihre Probleme: 1. Deskriptivstatistische Verfahren sind subjektiv 2. Inferenzstatistische Verfahren haben eine geringe Power in kleinen Stichproben, was dazu führt, dass sie Verletzungen nicht zeigen. In größeren Stichproben haben sie eine hohe Power und werden auch bei geringfügigen Verletzungen signifikant. Das ist ungünstig, da die Verletzungen vor allem in kleinen Stichproben relevant sind. In großen Stichproben und balancierten Designs sind Verfahren wie die ANOVA einigermaßen robust gegen einige der Verletzungen.

Ich persönlich würde die deskriptivstatistischen Verfahren empfehlen. Im Zweifel kann man diese in Kombination mit inferenzstatistischen Verfahren verwenden.

#### Was tun bei Verletzungen?

Verletzungen sollten immer transparent berichtet werden. Informiere dich darüber, wie sensibel das verwendete statistische Verfahren auf solche Verletzungen reagiert. Falls Korrekturen vorgenommen werden (z.B. robuste Tests, Transformationen), ist es sinnvoll, die Analyse mit und ohne Korrektur durchzuführen und beide Ergebnisse anzugeben. Ein robuster Effekt sollte sich unter beiden Bedingungen zeigen. Dies ist z.B. hilfreich, wenn unklar ist, ob Ausreißer das Ergebnis verzerren. Ergänzend können simulationsbasierte Verfahren wie Bootstrapping oder Randomization Tests eingesetzt werden. Diese reduzieren die Abhängigkeit von theoretischen Annahmen und können die Robustheit der Ergebnisse erhöhen.
:::

#### Normalverteilung

##### Histogramm

Mit einem Histogramm pro Gruppe können wir die Annahme der Normalverteilung grob untersuchen.

```{r label=fig-ggplothistttest}
df_bedingung <- df %>% filter(!is.na(bedingung))

ggplot(data = df_bedingung, mapping = aes(x = Gewissenhaftigkeit)) + 
  geom_histogram(bins = 20, color = "black", fill = "steelblue") +
  facet_wrap(~ bedingung) +
  labs(title = "Histogram", y = "Häufigkeit")
```

##### QQ-Plot

Die Normalverteilung können wir mit QQ-Plots testen. Im QQ-Plots wird die Verteilung der Residuen der Stichprobe (durch Punkte gekennzeichnet) mit der Normalverteilung (Strich) verglichen. Die Gerade kennzeichnet eine perfekte Normalverteilung. Je stärker die Punkte von der Linie abweichen, desto stärker weichen die Daten von der Normalverteilung ab.

Im Fall des t-Tests, indem man traditionell nicht von Residuen spricht, kann man die Werte der Personen pro Gruppe plotten. Das Package `Rempsyc` eine praktische Funktion für QQ-Plots.

###### QQ-Plot für Gewissenhaftigkeit, für die Kontrol- und Experimentalbedingung

```{r label=fig-remqqttest, fig.width=7, fig.height=5}
nice_qq(df_bedingung, variable = "Gewissenhaftigkeit", group = "bedingung", title = NULL)
```

#### Varianzhomogenität

Diese müssen wir im Fall vom t-Test über zwei unabhängige Stichproben testen. Hier können wir den Levene's Test verwenden. Dieser testet die $H_0$, dass die Varianzen der Gruppen homogen sind. Ein signifikanter Wert deutet darauf hin, dass die Varianzen heterogen sind, also eine Verletzung der Annahme der Homoskedastizität.

```{r levene, warning=FALSE}
leveneTest(Gewissenhaftigkeit ~ bedingung, data = df)
```

Die `t.test()`-Funktion testet per default, ob die Varianzen homogen sind. Bei einer Verletzung wird automatisch der Welch-Test verwendet

Allgemein ist der t-Test ziemlich robust gegenüber Verletzungen der Voraussetzungen.

# Varianzanalyse (ANOVA)

Klassischerweise wird für die ANOVA häufig die Funktion `aov()` verwendet. Im Folgenden werden wir jedoch das Package `afex` nutzen, da dies u.a. Vorteile bei unbalancierten Stichproben und bei Messwiederholung (Within-Subject) hat. Hier können wir die Funktion `aov_ez()` verwenden.

Die `aov_ez()` Funktion benötigt allerdings eine Participant-ID (`id =`). Im Fall einer Messwiederholung ermöglich dies, dass die Zeilen eines Participants im long Format richtig zugeordnet werden können. Falls keine ID vorhanden ist, können wir sie einfach hinzufügen, wenn es eine Zeile pro Participant gibt (wide Format). Wir zählen von 1 bis zur Gesamtanzahl der AV-Werte (`df_2_wide$wellbeing_t2)`) und fügen diese als `participant_id` hinzu. Gibt es einen Within-Subject Factor und die Daten sind im long Format (siehe @tbl-longwide) ist das etwas komplizierter: bei einer Messwiederholung mit $m$ Stufen bedeutet das $m$ Zeilen pro Participant.

```{r, warning=FALSE}
# Wide Format: ID Spalte pro Participant hinzufügen
df_2_wide$participant_id <- c(1:length(df_2_wide$wellbeing_t2))

# Long Format: ID Spalte pro Participant hinzufügen 
## Nur in Balancierten Design!
df_2_long$participant_id <- rep(seq_len(nrow(df_2_long) / length(unique(df_2_long$time))), each = length(unique(df_2_long$time)))

```

Zudem sollten wir die UV's der ANOVA zu einem Faktor konvertieren:
```{r}
# Between-UV's zu Faktor konvertieren
df_2_wide$therapy_group <- df_2_wide$therapy_group %>% as_factor()
df_2_wide$gender <- df_2_wide$gender %>% as_factor()
df_2_wide$therapy <- df_2_wide$therapy %>% as_factor()

# Between-UV's zu Faktor konvertieren
df_2_long$therapy_group <- df_2_long$therapy_group %>% as_factor()
df_2_long$gender <- df_2_long$gender %>% as_factor()
df_2_long$therapy <- df_2_long$therapy %>% as_factor()
```

### One Between

In R wird klassicherweise die Funktion `aov()` für die ANOVA verwendet. Da die Berechnung der Quadratsummen in `aov()` etwas anders geschieht als in anderen Programmen wie SPSS (Typ II vs. Typ III Quadratsummen), beschränke ich mich in diesem Skript auf die Funktion `aov_ez()` aus dem `afex`-Package.

Wir untersuchen, wie sich verschiedene Therapieformen – keine Therapie, kognitiv-behaviorale Therapie (CBT) und Gestalt-Therapie – auf das Well-Being auswirken. Zur Veranschaulichung einer ANOVA mit einem Between-Subjects-Faktor betrachten wir ausschließlich den Messzeitpunkt t2 und ignorieren die anderen Zeitpunkte (t0 und t1), die einen Within-Subjects-Faktor bilden würden. Die abhängige Variable ist somit wellbeing_t2.

Unter `ges` wird das Eta-Quadrat ausgegeben.

```{r}
anova_bet <- aov_ez(id = "participant_id", dv = "wellbeing_t2", between = "therapy_group", data = df_2_wide)

anova_bet

# Alternativ mit aov()
#aov(wellbeing ~ therapy, data = df_2_long)
```

### One Within

Für die ANOVA mit Messwiederholung (Within-Subject Factor) können wir die Funktion `aov_ez()` aus dem `afex()`-Package verwenden. Diese hat den Vorteil, dass sie bei Verletzung der Spherizität korrigierte Ergebnisse angibt. Im Folgenden Output wird darauf hingewiesen, dass nach einer Verletzung der Spherizität eine Greenhouse-Geisser-Korrektur angewandt wurde. Das können wir auch daran erkennen, dass die Freiheitsgrade keine ganzen Zahlen sind.

```{r}
anova_within <- aov_ez(id = "participant_id", dv = "wellbeing", within = "time", anova_table = list(es = "pes"), data = df_2_long)
anova_within
```

```{r fig-boxplottanova}
ggplot(df_2_long, aes(x = time, y = wellbeing, fill = time)) +
  geom_boxplot(alpha = 0.6, outlier.color = "red", outlier.shape = 16) +
  labs(title = "Well-being über Zeit",
       x = "Zeitpunkt",
       y = "Well-being Score") +
  theme_minimal() +
  theme(legend.position = "none")  # Remove legend
```

### Two Between

```{r}
anova_2_bet <- aov_ez(id = "participant_id", dv = "wellbeing_t2", between = c("therapy_group", "gender"), data = df_2_wide, anova_table = list(es = "pes"))
anova_2_bet

# Alternativ mit aov()
#anova_result <- aov(wellbeing_t2 ~ gender * therapy_group, data = df_2_wide)
```

#### Interaction Plot

Mit `interaction.plot(UV_1, UV_2, AV)` können wir einen Interaktions-Plot erstellen

```{r label=fig-interactionanova, fig.width=7, fig.height=4}
interaction.plot(df_2_wide$therapy_group, df_2_wide$gender, df_2_wide$wellbeing_t2, col = c("blue", "red"), 
                 lty = 1, lwd = 2, legend = TRUE, xlab = "Art der Therapie", ylab = "Well-being zu Zeitpunkt 2", trace.label = "")
```

### One Between, One Within (Mixed)

Für die ANOVA mit Messwiederholung (Within-Subject Factor) können wir wieder die Funktion `aov_ez()` verwenden. Diese hat den Vorteil, dass sie bei Verletzung der Spherizität automatisch korrigierte Ergebnisse angibt.

Hinweis: im folgenden Teil `anova_table = list(es = "pes")` geben wir mit `"es = pes"` das partielle Eta-Quadrat aud ($\hat \eta_{par}^2$). Wir können uns auch das generalisierte Eta-Quadrat ($\hat \eta^2$) ausgeben (`es = "ges"`).

```{r}
anova_mixed <- aov_ez(id = "participant_id", dv = "wellbeing", within = "time", between = "therapy_group", data = df_2_long, anova_table = list(es = "pes"), include_aov = TRUE)

summary(anova_mixed)
```

```{r label=fig-interactionanova2, fig.width=7, fig.height=4}
interaction.plot(df_2_long$time, df_2_long$therapy_group, df_2_long$wellbeing, col = c("purple", "orange", "green"),
                 legend = TRUE, lwd = 2, xlab = "Zeit", ylab = "Well-being", trace.label = "Therapie" )
```

Die Interaktionsplots können mit `interaction.plot()` leicht erstellt werden. Für detailliertere Grafiken bietet `ggplot()` allerdings deutlich mehr Optionen.

```{r}
ggplot(df_2_long, aes(x = time, y = wellbeing, color = therapy_group, group = therapy_group)) +
  stat_summary(fun = mean, geom = "point", size = 2) +
  stat_summary(fun = mean, geom = "line") +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2) +
  labs(title = "Well-Being über Zeit in Abhängigkeit von der Therapie ",
       x = "Zeit",
       y = "Well-Being")
```

## Effektgrößen


| $\eta^2$ | Interpretation   |
|----------|------------------|
| ≈ 0.01   | Kleiner Effekt   |
| ≈ 0.06   | Mittlerer Effekt |
| ≈ 0.14   | Großer Effekt    |

: Interpretation von Eta-Quadrat nach Konventionen (Cohen, 1988). {#tbl-eta}

Das partielle Eta-Quadrat $\hat \eta_{par}^2$ können wir in der Funktion `aov_ez()` mit ausgeben lassen `aov_ez(..., anova_table = list(es = "pes")`. Alternativ können wir es aus den Ergebnissen der gerechneten Varianzanalyse berechnen. Hierfür können wir die `eta_squared()`-Funktion aus dem Package `effectsize` verwenden. Diese berechnet zusätzlich ein 95%-iges Konfidenzintervall. Mit dem Parameter `partial = TRUE`, bzw. `generalized = TRUE` können wir uns speziell für das partielle oder generalisierte Eta-Quadrat entscheiden.

```{r eta_sq}
effectsize::eta_squared(anova_mixed)
```

Das Omega-Quadrat $\hat \omega^2_{par}$ ist eine korrigierte Alternative zum Eta-Quadrat. Das Eta-Quadrat (partiell oder generalisiert) ist positiv gebiased: unsystematische Zufallsvarianz wird zum Teil für systematische Effektvarianz gehalten. Daher wird das partielle Omega-Quadrat korrigiert und fällt i.d.R. kleiner aus als das partielle Eta-Quadrat. Wenn $\hat \omega^2_{par}$ negativ ausfällt, ist es auf 0.00 zu setzen.

```{r}
omega_squared(anova_mixed)
```

## Geplante Vergleiche / Post-Hoc Tests

### Geplante Kontraste

Anders als bei post-hoc Tests werden geplante Kontraste (Vergleiche) formuliert, bevor wir unsere Analysen rechnen bzw. die Daten begutachten. Das bedeutet, wir formulieren eine Hypothese und testen sie dann mit unseren Daten. Solche Erkenntnisse sind deutlich schwerer zu gewichten als Erkenntnisse, auf die wir bei Analyse der Daten explorativ stoßen. Geplante Kontraste sind im Prinzip wie ein t-Test. Wenn man mehr als zwei Gruppen vergleicht, kann man jedoch die unbekannte Populationsvarianz besser schätzen. Daher verfügen geplante Kontraste über eine höhere Power als wenn man alternativ nur einzelne t-Tests rechnen würde.

Wir untersuchen am Beispiel der Anova mit einem Between-Subject Factor die a-priori formulierte Hypothese, dass sich Personen mit Kognitiv-behavioraler Therapie von Patient\*innen mit Gestalt-Therapie nach der Intervention (Zeitpunkt 2) unterscheiden, unabhängig von Patient\*innen auf der Warteliste (ohne Therapie). Hierfür müssen wir die Mittelwerte mit Kontrastgewichten versehen. Zu erst erstellen wir die "Estimated Marginal Means" und schauen, wie die Levels unseres Faktors geordnet sind. Dadurch wissen wir, wie wir sie im nächsten Schritt gewichten müssen.

Wir gewichten den Mittelwert von Gruppe 2 (CBT) mit +1, den von Gruppe 3 (Gestalt) mit -1. Da uns Gruppe 1 (keine Therapie) in diesem Vergleich nicht interessiert, wird ihr Mittelwert mit 0 gewichtet. Wir können mit `contrast()` die Kontraste eines Faktors manuell überschreiben. Dem Vergleich von kognitiv-behavioraler Therapie vs. Gestalt-Therapie geben wir den Namen "CBT_vs_Gestalt" und legen die Gewichte wie beschrieben fest: `c(0, 1, -1)`.

$H_0: 0 \cdot \mu_{kontroll} + 1  \cdot \mu_{gestalt} - 1 \cdot \mu_{CBT} = 0$

```{r}
# One Between ANOVA
anova_bet <- aov_ez(id = "participant_id", dv = "wellbeing_t2", between = "therapy_group", data = df_2_wide, anova_table = list(es = "pes"))

# Estimated marginal means
estimated_marginal_means <- emmeans(anova_bet, ~ therapy_group)
estimated_marginal_means

levels(df_2_wide$therapy_group)

# Kontrast festlegen 
contrast_custom <- contrast(estimated_marginal_means, method = list("CBT_vs_Gestalt_t2" = c(0, 1, -1)))
summary(contrast_custom)
```

Mit der folgenden `rempsyc`-Funktion können wir uns für alle Kontraste, Cohen's d ausgeben lassen und mittels Bootstrapping Konfidenzintervalle erstellen lassen. Diese sind allerdings nicht in Hinsicht auf Multiples Testen korrigiert und es werden alle möglichen Kontraste angegeben, also auch solche, die nicht unbedingt a-priori geplant wurden.

```{r}
set.seed(100) # for reproducability
nice_contrasts(data = df_2_wide, response = "wellbeing_t2", group = "therapy_group", effect.type = "cohens.d", bootstraps = 1000)
```

#### Komplexe Kontraste

In komplexen Kontrasten vergleichen wir anders als bei paarweisen Vergleichen nicht eine Bedingung mir einer anderen, sondern beispielsweise eine Bedingung mit zwei anderen Bedingungen. Wir wollen untersuchen, ob sich Patient\*innen auf der Warteliste, also ohne Therapie (Gruppe 1) von Personen unterscheiden, die in Therapie sind (Gruppen 2 & 3). Wir gewichten den Mittelwert von Gruppe 1 mit 1 und jene von Gruppen 2 & 3 mit jeweils -0.5. Auf beiden Seiten müssen die Werte gleich groß sein (1 vs. -(0.5+0.5)). Der Wert von 0.5 statt 1 sorgt dafür, dass die Mittelwerte von Gruppen 2 & 3 gemittelt werden (2 \* 0.5 = 1). Das negative Vorzeichen bestimmt, welche Gruppe auf welcher Seite des Kontrasts steht. Welche Gruppe negativ bzw. positiv gewichtet wird, ist uns überlassen.

$H_0: 1 \cdot \mu_1 - 0.5  \cdot \mu_2 + 0.5  \cdot \mu_3 = 0$

```{r}
anova_bet <- aov_ez(id = "participant_id", dv = "wellbeing_t2", between = "therapy_group", data = df_2_wide, anova_table = list(es = "pes"))

contrast_matrix <- contrast(estimated_marginal_means,
                            method = list("Waiting_list_vs_Therapy" = c(1, -0.5, -0.5)))
summary(contrast_matrix)
```

Hinweis: es gibt eine alternative Version, um Kontrast mit der weit verbreiteten Funktion zur Varianzanalyse (`aov()`) zu rechnen: mit `aov()` $\rightarrow$ `contrasts()` $\rightarrow$ `summary.lm()`.

#### Bonferoni

In der Bonferoni-Korrektur wird gegen Multiples Testen korrigiert, indem jeder p-Wert eines Vergleichs mit der Anzahl der Vergleiche multipliziert wird ($N * p_j \leq \alpha'$), oder alternativ dass das Signifikanzniveau $\alpha$ durch die Anzahl der Vergleiche geteilt wird ($p_j \leq \frac{\alpha'}{N}$). Hier gilt daher: Je mehr Vergleiche wir durchführen, desto geringer muss ein Signifikanzniveau sein, um signifikant zu werden. Daher ist es sinnvoll, sich die Vergleiche genau zu überlegen und nicht alle möglichen Vergleiche zu rechnen.

Dadurch ist dieses Kriterium konservativer als beispielsweise die Tukey-Kramer Korrektur. Die einzelnen Hypothesen müssen allerdings nicht unabhängig sein.

Unter `$contrasts` werden die Vergleiche der einzelnen Stufen angegeben. Unter `$emmeans` bekommen wir die geschätzten Mittelwerte für jede Stufe.

```{r}
# Bonferoni
anova_mixed <- aov_ez(id = "participant_id", dv = "wellbeing", within = "time", between = "therapy_group", 
                      data = df_2_long, anova_table = list(es = "pes"), include_aov = TRUE)

emm_mixed <- emmeans(anova_mixed, ~ therapy_group * time)
as.data.frame(emm_mixed) # Reihenfolge der Kontraste überprüfen
```

In der vorliegenden Mixed ANOVA erhalten wir für jedes Level des Between-Subject Factors zu jedem Level des Within-Subject Factors den Estimated Marginal Mean. Nun wählen wir basierend auf der vorherigen Reihenfolge diejenigen aus, welche wir vergleichen wollen:

```{r}
anova_mixed_contrasts <- contrast(
  emm_mixed,
  method = list(
    "CBT_vs_Gestalt_t2" = c(0, 0, 0, 0, 0, 0, 1, -1, 0),  
    "Waiting_list_vs_Therapy_t2" = c(0, 0, 0, 0, 0, 0, 0.5, 0.5, - 1) ),
  adjust = "bonferroni"
)

summary(anova_mixed_contrasts)
```

### Post-Hoc Tests

##### Tukey HSD

Die Tukey-Kramer-Korrektur ist ein Verfahren zur Kontrolle des Fehlerniveaus bei multiplen paarweisen Vergleichen von Faktorstufen, insbesondere im Rahmen von Post-hoc-Analysen nach einer signifikanten ANOVA. Die Korrektur schützt vor Multiplen Testen, indem sie die Signifikanzschwelle am größten möglichen Unterschied aller Gruppen orientiert – also an der extremsten Konstellation. Wenn beispielsweise der größte Unterschied zwischen CBT und keiner Therapie besteht, bemessen wir daran, wie hoch andere Unterschiede sein müssen, um signifikant zu werden. Im Vergleich zur Bonferroni-Korrektur oder zum Scheffe-Test ist die Power der Tukey-Korrektur höher, d.h., kleinere Effekte können eher erkannt werden. Ein weiterer Vorteil ist, dass die einzelnen Hypothesentests nicht unabhängig voneinander sein müssen.

```{r}
emm_only_t2 <- emmeans(anova_mixed, ~ therapy_group, at = list(time = "wellbeing_t2"))
pairs(emm_only_t2, adjust = "tukey")
```

Wir können auch einen Plot mit simultanen Konfidenzintervallen anzeigen lassen. Dabei handelt es sich um Konfidenzintervalle, die für multiples Testen korrigiert sind (family-wise). Hier auf Basis von Tukey’s Honest Significant Difference (HSD):

Hinweis: Im folgenden Beispiel verwenden wir nicht die `aov_ez()` Funktion mit `emmeans()` sondern die `aov()`-Funktion mit `TukeyHSD()`. Die genannten Funktionen stammen aus unterschiedlichen Packages und sind zum Teil nicht kompatibel.

```{r label=fig-confidenceintervalplots}
aov_2_bet <- aov(wellbeing_t2 ~ therapy_group + gender, data = df_2_wide)

posthoc_tukey_2 <- TukeyHSD(aov_2_bet)

# Just for plotting
par(mar = c(5, 13.5, 4, 2))

plot(posthoc_tukey_2, las = 1)
```

##### Scheffe Test

```{r}
# Scheffe Post-Hoc Test
pairwise_scheffe <- emmeans(aov_2_bet, pairwise ~ therapy_group + gender, adjust = "scheffe")
pairwise_scheffe
```

## Voraussetzungen ANOVA

::: callout-tip
## Statistische Voraussetzungen

Beim Testen der Voraussetzungen können wir entweder deskriptivstatistische oder inferenzstatistische Verfahren verwenden. Deskriptivstatistisch kann man die Verfahren mit Plots untersuchen (z.B. Residual Plots, QQ Plots). Inferenzstatistiche Verfahren werden mit Tests durchgeführt (z.B. Kolmogorov-Smirnov Test). Beide Herangehensweisen haben ihre Probleme: 1. Deskriptivstatistische Verfahren sind subjektiv 2. Inferenzstatistische Verfahren haben eine geringe Power in kleinen Stichproben, was dazu führt, dass sie Verletzungen nicht zeigen. In größeren Stichproben haben sie eine hohe Power und werden auch bei geringfügigen Verletzungen signifikant. Das ist ungünstig, da die Verletzungen vor allem in kleinen Stichproben relevant sind. In großen Stichproben und balancierten Designs sind Verfahren wie die ANOVA einigermaßen robust gegen einige der Verletzungen.

Ich persönlich würde die deskriptivstatistischen Verfahren empfehlen. Im Zweifel kann man diese in Kombination mit inferenzstatistischen Verfahren verwenden.

#### Was tun bei Verletzungen?

Verletzungen sollten immer transparent berichtet werden. Informiere dich darüber, wie sensibel das verwendete statistische Verfahren auf solche Verletzungen reagiert. Falls Korrekturen vorgenommen werden (z.B. robuste Tests, Transformationen), ist es sinnvoll, die Analyse mit und ohne Korrektur durchzuführen und beide Ergebnisse anzugeben. Ein robuster Effekt sollte sich unter beiden Bedingungen zeigen. Dies ist z.B. hilfreich, wenn unklar ist, ob Ausreißer das Ergebnis verzerren. Ergänzend können simulationsbasierte Verfahren wie Bootstrapping oder Randomization Tests eingesetzt werden. Diese reduzieren die Abhängigkeit von theoretischen Annahmen und können die Robustheit der Ergebnisse erhöhen.
:::

### Homoskedastizität (Varianzhomogenität)

Homoskedastizität ist die eine zentrale Annahme in der ANOVA: die Varianzen in den Gruppen sind gleich, bzw. ähnlich groß ("homogen"). Eine Verletzung der Homoskedastizität ist schwerwiegender wenn die Gruppen unterschiedlich groß sind.

#### Residual Plot

Um die Homoskedastizität zu überprüfen, erstellen wir einen Residual Plot. Die Residuen bezeichnen Abweichungen eines beobachteten Wertes vom vorhergesagten Wert. In der ANOVA ist das die Abweichung eines Wert $y_{ij}$ vom jeweiligen Gruppenmittelwert $\hat y_j$. Daher: $e_{ij} = y_{ij} - \hat y_j$. Im folgenden Residual Plot für eine 2x3 ANOVA mit zwei Between-Subjects Factors haben wir sechs Untergruppen. Das zeigt sich in sechs verschieden "fitted" Values, also den jeweiligen Gruppenmittelwerten. Die Residuen sind als Abweichungen von den jeweiligen fitted Values zu sehen.

Wir wollen, dass die Varianz in allen Gruppen ähnlich groß ist. Daher schauen wir uns an, ob die Residuen ähnlich um 0 streuen. Zudem zeigt der Residual Plot potentielle Ausreißer.

```{r label=fig-residualplotanova}
anova_2_bet <- aov_ez(id = "participant_id", dv = "wellbeing_t2", between = c("therapy_group", "gender"), data = df_2_wide, anova_table = list(es = "pes"))

# Extract residuals and fitted values
residuals <- residuals(anova_2_bet)
fitted_values <- fitted(anova_2_bet)

# Plot residuals against fitted values
plot(jitter(fitted_values), residuals, 
     xlab = "Fitted Values", 
     ylab = "Residuals", 
     main = "Residuals of Sub-Groups")
  abline(h = 0, col = "red") 
```

Siehe @fig-residuenplotregression für einen Residual Plot in der Regression.

#### Levene's Test

Alternativ können wir den Levene's Test verwenden. Dieser testet die $H_0$, dass die Varianzen der Gruppen homogen sind. Ein signifikanter Wert deutet darauf hin, dass die Varianzen heterogen sind, also eine Verletzung der Annahme der Homoskedastizität.

```{r}
leveneTest(wellbeing_t2 ~ therapy_group*gender, data = df_2_wide)
```

### Spherizität

Spherizität ist eine Erweiterung der Homoskedastizität bei Messwiederholungs-Designs (mit Within-Subject Factor). Die Spherizität beschreibt, dass die Varianz der Differenzen zwischen den Messzeitpunkten konstant ist. Ein einfaches Beispiel wäre der IQ gemessen im Alter von 17, 18 und 30 Jahren. Die Messungen im Alter von 17 und 18 Jahren würden sich deutlich weniger unterscheiden (=geringere Varianz der Differenzen) als beispielsweise bei 18 und 30 Jahren.

$H_0 = \sigma^2_{y_1 - y_2} = \sigma^2_{y_1 - y_3} = \sigma^2_{y_2 - y_3}$

$H_1 = \sigma^2_{y_1 - y_2} \not = \sigma^2_{y_1 - y_3} \not = \sigma^2_{y_2 - y_3}$

Wenn wir uns die `summary()` einer ANOVA mit `aov_ez()` ausgeben, sehen wir zunächst die nicht-korrigierten Ergebnisse. Darunter wird uns bei `Mauchly Tests for Sphericity` eine Verletzung der Spherizität angezeigt ($p<.05$). Es wird jeweils ein Greenhouse-Geisser und Huynh-Feldt Epsilon zur Korrektur angegeben. Wenn wir uns einfach nur das `aov_ez()`-ANOVA Objekt ausgeben lassen, sind die Ergebnisse bei Verletzung der Spherizität automatisch korrigiert: Die Freiheitsgrade des F-Tests sind mit dem Greenhouse-Geisser Epsilon multipliziert.

```{r}
anova_within <- aov_ez(id = "participant_id", dv = "wellbeing", within = "time", anova_table = list(es = "pes"), data = df_2_long)
summary(anova_within)
```

```{r}
anova_within
```

### Normalverteilung

::: callout-tip
Die ANOVA ist einigermaßen robust gegen eine Verletzung der Normalverteilung, es sei denn die Verteilung ist in der Population sehr schief oder Gruppengrößen sind unterschiedlich groß. Hierbei ist es relevant, dass die Messwerte, bzw. Residuen, in den Gruppen normalverteilt sind, nicht die Daten allgemein (Stellen Sie sich bei drei Gruppen z.B. drei Normalverteilungen vor, die zum Teil überlappen. Die Daten wären nicht normalverteilt, in den Gruppen aber schon.)
:::

#### Histogram

Mit einem Histogramm pro Gruppe können wir die Annahme der Normalverteilung grob untersuchen. Hierfür können wir die Residuen oder die Werte pro Gruppe verwenden.

```{r label=fig-ggplothist}
ggplot(data = df_2_wide, mapping = aes(x = wellbeing_t2)) + 
  geom_histogram(bins = 20, color = "black", fill = "steelblue") +
  facet_wrap(~ therapy_group) +
  labs(title = "Histogram", y = "Häufigkeit")
```

#### QQ-Plot

Die Normalverteilung können wir mit QQ-Plots testen. Im QQ-Plots wird die Verteilung der Residuen der Stichprobe (durch Punkte gekennzeichnet) mit der Normalverteilung (Strich) verglichen. Die Gerade kennzeichnet eine perfekte Normalverteilung. Je stärker die Punkte von der Linie abweichen, desto stärker weichen die Daten von der Normalverteilung ab.

```{r label=fig-qqplotanova}
# Wir haben die Residuen zuvor extrahiert: residuals <- residuals(anova_result)
df_2_wide$residual <- residuals

qqnorm(df_2_wide$residual, main = "QQ-Plot")
qqline(df_2_wide$residual)
```

Das Package `Rempsyc` eine praktische Funktion für QQ-Plots. Hier können wir (bei Bedarf) auch einstellen, dass wir die Verteilungen der einzelnen Gruppen untersuchen wollen.

```{r label=fig-remqq}
nice_qq(df_2_wide, variable = "residual", title = NULL)
```

#### Shapiro Wilk Test

Zur Überprüfung der Normalverteilungsannahme der Residuen können wir auch einen inferenzstatistischen Test, wie den Shapiro-Wilk-Test, verwenden. Dabei testen wir, ob die Residuen innerhalb jeder Gruppe (nicht die abhängige Variable insgesamt!) signifikant von einer Normalverteilung abweichen.

```{r shapiro}
shapiro.test(residuals)
```

### Unabhängigkeit der Residuen

Die Annahme der Unabhängigkeit ist verletzt, wenn sich systematische Abhängigkeiten in den Daten ergeben, die im Modell nicht berücksichtigt werden. Wenn Teilnehmende der kognitiv-behavioralen und Gestalt-Therapie aus unterschiedlichen Praxen rekrutiert wurden, könnten sich Clustereffekte ergeben – etwa durch unterschiedliche Therapeut\*innen oder Standorte. Solche Abhängigkeiten führen zu korrelierten Residuen innerhalb der Cluster, was gegen die Unabhängigkeitsannahme verstößt.

Da sich Unabhängigkeit nicht direkt statistisch testen lässt, wird sie primär über das Studiendesign beurteilt. Bei Hinweisen auf Clusterbildung sind komplexere Mixed-Effects-Modelle geeigneter als die ANOVA.

### Ausreißer

Ausreißer können das Ergebnis der ANOVA stark beeinflussen. Wir können den Residual Plot (@fig-residualplotanova) oder Box-Plot (@fig-boxplottanova) nutzen, um Ausreißer zu identifizieren.

::: callout-tip
Das Ausschließen von Ausreißern ist ein kontroverses Thema. Im Zweifel lohnt es sich, zu untersuchen ob der Effekt auch ohne Ausreißer oder in einem rang-basierten Verfahren besteht. Zudem kann Bootstrapping verwendet werden, um die Robustheit der Ergebnisse zu bestärken.
:::

# Korrelation

| $r$ (Pearson) | Interpretation   |
|---------------|------------------|
| ≈ 0.10        | Kleiner Effekt   |
| ≈ 0.30        | Mittlerer Effekt |
| ≈ 0.50        | Großer Effekt    |
: Interpretation der Pearson-Korrelation $r$ nach Konventionen (Cohen, 1988). {#tbl-Cohen_r}


Mittels `cor()` können wir den Korrelationskoeffizienten berechnen. Im Parameter `use` können wir angeben, wie wir mit fehlenden Werten (`NA`) umgehen wollen.

```{r}
cor(df$Extraversion, df$Neurotizismus, use = "complete.obs")
```

Mit `cor.test()` können wir auf Signifikanz testen. Zudem wird automatisch ein `95%`-Konfidenzintervall ausgegeben

```{r}
cor.test(df$Extraversion, df$Neurotizismus)

cor_ex_neu <- cor.test(df$Extraversion, df$Neurotizismus, use = "complete.obs", method = "pearson")

r_value <- cor_ex_neu$estimate  # Pearson-Korrelation (r)
p_value <- cor_ex_neu$p.value    # p-value
ci_lower <- cor_ex_neu$conf.int[1]  # Untere Grenze des 95% KI
ci_upper <- cor_ex_neu$conf.int[2]  # Obere Grenze des 95% KI
```

#### Rangkorrelation

Im Parameter `method` können wir ebenfalls die Spearman-Korrelation und Kendall's Tau auswählen, welche Rang-basiert sind.

```{r}
cor.test(df$Extraversion, df$Neurotizismus, method = "spearman")
cor.test(df$Extraversion, df$Neurotizismus, method = "kendall")
```

#### Korrelationsmatrix

Es gibt verschiedene Möglichkeiten, eine Korrelations-Matrix oder Scatterplot-Matrix erstellen zu lassen:

1.  Die `cor()`-Funktion mit mehreren Spalten eines Dataframes.

```{r}
cor(df[, c("IQ", "numerical_ability", "WMS4_delayed_recall")], method = "pearson", use = "pairwise.complete.obs")
```

2.  `ggpairs()` aus dem `GGally`-Package.

Hier können wir uns eine Hälfte der Matrix als Scatterplot Matrix ausgeben lassen (unter `lower`). Die `method` gibt hier an, ob die Regressionslinie gerade sein soll (`method = "lm"`) oder eine "lokale", daher nicht-gerade Regressionslinie (`method = "loess"`). Letzteres ist sinnvoll, um die Voraussetzung der **Linearität** überprüfen will. Zusätzlich kann man sich den Standardfehler der Regressionslinie angeben lassen (`se = TRUE`).

```{r label=fig-ggpairscorplot, message=FALSE, warning=FALSE}
ggpairs(df, columns = c("IQ", "numerical_ability", "WMS4_delayed_recall"),
        lower = list(continuous = wrap("smooth", method = "loess", se = TRUE)),
        upper = list(continuous = wrap("cor")
        )
)
```

3.  Das `psych()`-Package bietet eine ähnliche Funktion.

```{r label=fig-psychcorplot}
pairs.panels(df[, c("IQ", "numerical_ability", "WMS4_delayed_recall")], ellipses = F)
```

# Regression

### Einfache Lineare Regression

Die Syntax der Einfachen Linearen Regression ist im selben Schema wie zuvor: `AV ~ UV`. Über `summary()` können wir uns wieder die Ergebnisse ausgeben lassen.

Das unstandardisierte Regressionsgewicht von IQ ist unter `Estimate` zu finden. Daneben den zugehörigen Standardfehler, t-Wert und zugehörigen p-Wert. Das `Multiple R-squared` entspricht dem $R^2$, der gesamten durch das Modell aufgeklärten Varianz.

```{r}
model_simple_regression <- lm(IQ ~ WMS4_delayed_recall, data = df)

summary(model_simple_regression)
```

Die standardisierten Regressionskoeffizienten, also der $\beta$-Koeffizient, werden leider nicht automatisch mit ausgegeben. Mit dem Package `lm.beta` können wir diese bekommen. In der einfachen linearen Regression sind diese identisch mit der Pearson-Korrelation. Die ist in der MLR nicht der Fall, es sei denn die Prädiktoren haben keine gemeinsame Varianz.

```{r}
lm.beta(model_simple_regression)
cor(df$IQ, df$WMS4_delayed_recall)
```

Wir können uns auch die Übersicht über das gesamte Model inkl. der standardisierten Regressionskoeffizienten unter `Standardized` ausgeben lassen:

```{r}
summary(lm.beta(model_simple_regression))
```

Wir können uns ganz einfach ein Konfidenzintervall für unser unstandardisiertes Regressionsgewicht angeben lassen:

```{r}
confint(model_simple_regression)
```

Das Package `rempsyc` bietet nützliche Funktionen, um Ergebnis-Tabellen zu erstellen. Diese sind zum Großteil APA-konform. Ich rate jedoch, das Format bei Verwendung noch einmal zu überprüfen.

```{r}
model_slr_results <- nice_lm(model_simple_regression)
model_slr_results[2] <- "WMS4 delayed recall" # WMS als Prädiktor
model_slr_results
```

```{r label=tbl-niceslr}
model_slr_results <- nice_table(model_slr_results, 
                                title = c("Tabelle 1", "Zusammenhang von Gedächtnisfähigkeit (verzögerte Wiedergabe) und Intelligenz"),
                                note = c(paste("Diese Tablle ist als Beispiel gedacht. Alle Zusammenhänge sind frei erfunden.", sep = " "), "* p < .05, ** p < .01, *** p < .001"))

#Um Tabelle als Word-Datei zu speichern
#flextable::save_as_docx(model_slr_results, path = "model_slr_results.docx")

model_slr_results
```

### Multiple Lineare Regression

$$Y_i = \alpha + \beta_1 \cdot x_{i1} + \beta_2 \cdot x_{i2} + \beta_3 (x_{i1} \cdot x_{i2}) + \epsilon_i$$

Die Syntax für die MLR bleibt gleich: wir fügen weiter Prädiktoren (UVs) mit `+` ein, sowie eine Interaktion durch `*`.

```{r}
model_mlr <- lm(IQ ~ numerical_ability + WMS4_delayed_recall + numerical_ability * WMS4_delayed_recall, data = df)
model_mlr_stan <- summary(lm.beta(model_mlr)) # für standardisiertes Regressionsgewicht

model_mlr_stan
```

```{r}
model_mlr_table <- tidy(model_mlr_stan)

colnames(model_mlr_table) <- c("Variable", "b", "β", "SE", "t", "p") # "\u03B2" kann statt β verwendet werden

model_mlr_table
```

Wir können uns ganz einfach das Konfidenzintervall zum unstandardisierten Regressionsgewicht ausgeben lassen:

```{r}
confint(model_mlr)
```

```{r label=tbl-nicemlr}
nice_table(model_mlr_table, 
           title = c("Tabelle 2", "Vorhersage der Intelligenz durch Gedächtnisfähigkeit (verzögerte Wiedergabe) und numerischen Fähigkeiten"),
           note = c(
             paste("Diese Tablle ist als Beispiel gedacht. Alle Zusammenhänge sind frei erfunden.", sep = " "), "* p < .05, ** p < .01, *** p < .001"))
```

Beim Vorliegen von diskreten Prädiktoren verweise ich auf das Kapitel "MLR mit diskreten Prädiktor".

## Voraussetzungen Regression

Die folgende Abbildung zeit die Relevanz der Prüfung der Voraussetzungen in der Regression. Jeder der vier Datensätze verfügt über die selbe Regressionsgerade und $R^2 = 0.67$. Links oben ($y_1$) ist keine der Voraussetzungen verletzt. Hier sind jedoch nicht alle Voraussetzungen abgebildet.

![](images/Anscombe's_quartet_3.svg){#fig-ascombe}

[Ascombe's Quartett auf Wikipedia](https://de.wikipedia.org/wiki/Anscombe-Quartett#/media/Datei:Anscombe's_quartet_3.svg)

::: callout-tip 
## Statistische Voraussetzungen

Beim Testen der Voraussetzungen können wir entweder deskriptivstatistische oder inferenzstatistische Verfahren verwenden. Deskriptivstatistisch kann man die Verfahren mit Plots untersuchen (z.B. Residual Plots, QQ Plots). Inferenzstatistiche Verfahren werden mit Tests durchgeführt (z.B. Kolmogorov-Smirnov Test). Beide Herangehensweisen haben ihre Probleme: 1. Deskriptivstatistische Verfahren sind subjektiv 2. Inferenzstatistische Verfahren haben eine geringe Power in kleinen Stichproben, was dazu führt, dass sie Verletzungen nicht zeigen. In größeren Stichproben haben sie eine hohe Power und werden auch bei geringfügigen Verletzungen signifikant. Das ist ungünstig, da die Verletzungen vor allem in kleinen Stichproben relevant sind. In großen Stichproben und balancierten Designs sind Verfahren wie die ANOVA einigermaßen robust gegen einige der Verletzungen.

Ich persönlich würde die deskriptivstatistischen Verfahren empfehlen. Im Zweifel kann man diese in Kombination mit inferenzstatistischen Verfahren verwenden.

#### Was tun bei Verletzungen?

Verletzungen sollten immer transparent berichtet werden. Informiere dich darüber, wie sensibel das verwendete statistische Verfahren auf solche Verletzungen reagiert. Falls Korrekturen vorgenommen werden (z.B. robuste Tests, Transformationen), ist es sinnvoll, die Analyse mit und ohne Korrektur durchzuführen und beide Ergebnisse anzugeben. Ein robuster Effekt sollte sich unter beiden Bedingungen zeigen. Dies ist z.B. hilfreich, wenn unklar ist, ob Ausreißer das Ergebnis verzerren. Ergänzend können simulationsbasierte Verfahren wie Bootstrapping oder Randomization Tests eingesetzt werden. Diese reduzieren die Abhängigkeit von theoretischen Annahmen und können die Robustheit der Ergebnisse erhöhen.
:::

### Homoskedastizität

#### Residual Plot

Ähnlich wie in der ANOVA können wir einen Residual Plot verwenden um die Homoskedastizität zu überprüfen (s. @fig-residualplotanova). Die Residuen sind Abweichungen eines beobachteten Wertes von dem vorhergesagten Wert. In der Regression ist das die Abweichung eines Wert $y_{i}$ vom bedingten Erwartungswert $E(y_i | X_i = x_i)$. Konkret bedeutet das die Abweichung eines Werts von der Regressionsgeraden (in y). Die Regressionsgerade gibt an, welchen y-Wert wird basierend auf dem x-Wert erwarten würden ($E(y_i | X_i = x_i)$). Daher: $e_{i} = y_{i} - \hat y_i$. Im nächsten Schritt standardisieren wir die Residuen. Hier können wir uns die standardisierten Residuen einfach ausgeben lassen `rstandard(model_mlr)`.

Ist die Varianzhomogenität gegeben, streuen die Werte zufällig um null. In diesem Fall zeigt sich das darin, dass wir keine Muster in den Residuen erkennen. Eine Verletzung anderer Voraussetzungen (Linearität, Unabhängigkeit der Messwerte, Ausreißer) kann sich ebenfalls im Residual Plot zeigen.

```{r label=fig-residuenplotregression}
# Extract standardized residuals and fitted values
residuals <- rstandard(model_mlr)
fitted_values <- fitted(model_mlr)

# Plot residuals against fitted values
plot(jitter(fitted_values), residuals, 
     xlab = "Fitted Values", 
     ylab = "Residuals", 
     main = "Residuals")
  abline(h = 0, col = "red") 

```

Hinweis: der Code für den obigen Residual Plot ist identisch zum Residual Plot der ANOVA (@fig-residualplotanova).

Alternativ können wir den Breusch-Pagan Test verwenden:

```{r}
library(lmtest)
bptest(model_mlr)
```

### Linearität

Um die Linearität zu überprüfen, können wir uns für die untersuchten Zusammenhänge Scatterplots mit lokalen Regressionslinien ("loess") untersuchen. Hier ist es empfehlenswert, sich den Scatterplot aus beiden Richtungen ausgeben zu lassen (beide Variablen jeweils auf der x und y-Achse). Wir können die Funktion zur Korrelationsmatrix aus @fig-ggpairscorplot anpassen, um die obere Hälfte ebenfalls mit Scatterplots zu füllen.

Bei einer starken Verletzung oder bei non-linearen Zusammenhängen, können wir komplexere Verfahren (z.B. non-lineare Regression, quadratische Regression) verwenden.

```{r label=fig-ggpairscatterplot, message=FALSE, warning=FALSE}
ggpairs(df, columns = c("IQ", "numerical_ability", "WMS4_delayed_recall"),
        lower = list(continuous = wrap("smooth", method = "loess", se = TRUE)),
        upper = list(continuous = wrap("smooth", method = "loess", se = TRUE)
        )
)
```

### Normalverteilung der Residuen

Um die Normalverteilung der Residuen zu untersuchen, können wir wieder ein Histogramm und einen QQ-Plot der Residuen erstellen. Der Code ist wieder identisch zum QQ-Plot in der ANOVA (@fig-qqplotanova).

```{r label=fig-qqplotregression}
# Wir extrahieren die residuen 
residuals_mult_regression <- residuals(model_mlr)

qqnorm(residuals_mult_regression, main = "QQ-Plot")
qqline(residuals_mult_regression)
```

```{r label=fig-histregression}
hist(rstandard(model_mlr))
```

Alternativ können wir die Schiefe und Kurtosis der Residuen überprüfen. Bei Vorliegen der Normalverteilung sind diese Werte nahe Null. Die absoluten Werte sollten $\leq 1$ sein. Die Kurtosis kann etwas höher ausfallen, sollte jedoch $\leq 5$ sein.

Schiefe:

```{r}
describe(residuals_mult_regression)$skew
```

Kurtosis:

```{r}
describe(residuals_mult_regression)$kurtosis
```

### Unabhängigkeit der Residuen

Das Regressionsmodell geht davon aus, dass die Fehler (Residuen) unkorreliert sind. Wenn diese korreliert sind, könnte in den Daten eine Beziehung vorliegen, welche wir im Modell nicht erfasst haben. Das würde dazu führen, dass wir verzerrte Standardfehler für unsere Regressionskoeffizienten erhalten. Insgesamt empfiehlt es sich, die Unabhängigkeit der Residuen visuell im Residuenplot (@fig-residuenplotregression) zu untersuchen. Wir wollen möglichst kein systematisches Muster erkennen.

Zusätzlich kann der Durbin-Watson Test verwendet werden, um die Abhängigkeit aufeinander folgender Residuen zu testen. Dieser testet die $H_0$, ob eine Autokorrelation der Residuen vorliegt.

```{r}
durbinWatsonTest(model_mlr)
```

### Ausreißer

Ausreißer können einen starken Einfluss auf die Regression haben (s. @fig-ascombe). Wir können sie ebenfalls im Residual Plot (@fig-residuenplotregression) oder in einem Scatterplot (@fig-ggpairscatterplot) identifizieren. Alternativ können wir festgelegte Kriterien anwenden, beispielsweise Werte ausschließen, welche z.B. 3 Standardabweichungen vom Mittelwert entfernt sind.

```{r label=fig-ausreißer}
# Mittelwert und Standardabweichung berechnen
mean_value <- mean(df$Alter)
sd_value <- sd(df$Alter)

# Absoluter Abstand mehr als 3 SD
df$outlier <- abs(df$Alter - mean_value) > (3 * sd_value)

# Optional: Visualize outliers
ggplot(df, aes(x = Alter, y = Offenheit)) +
    geom_point(aes(color = outlier), alpha = 0.6) +
    scale_color_manual(values = c("black", "red")) 
```

#### Multikollinearität

Multikollinearität ist nur relevant, wenn wir mehrere Prädiktoren verwenden. Multikollinearität liegt vor, wenn sich unsere Prädiktoren einen erheblichen Anteil an gemeinsamer Varianz teilen. Dies kann dazu führen, dass wir einen Effekte nicht mehr dem jeweiligen Prädiktor zuordnen können.

Zu erst sollten wir in einer Korrelationsmatrix überprüfen (s. @fig-ggpairscorplot), wie sehr unsere Prädiktoren korreliert sind. Hohe Korrelationen sind ein Indikator für Multikollinearität.

Zudem können wir den Variance Inflation Factor (VIF) der Prädiktoren überprüfen. Dieser wird folgendermaßen berechnet: $VIF_1 = \frac {1}{1- R^2_{1 \cdot 2 ... p}}$. 1 geteilt durch die Varianz im Prädiktor, welche nicht durch die andere Prädiktoren erklärt werden kann. Der VIF hat seinen Namen daher, dass er im Standardfehler des Regressionskoeffizienten enthalten ist und die Varianz, also auch den Standardfehler, in die Höhe treiben kann ("Inflation"). Dies kann dazu führen, dass wir Varianz im Modell aufklären können ($R^2 \geq 0$), aber keiner der Prädiktoren signifikant wird.

Häufig genannte Cutoff-Werte für den VIF sind $\leq$ 5 und $\leq$ 10. VIF $\leq$ 5 gilt als gut, VIF $\leq$ 10 gelten i.d.R. als okay.

```{r}
vif_values <- vif(model_mlr, type = "predictor")
vif_values
```

Die Toleranz wird in SPSS zusätzlich zum VIF angegeben. Sie gibt den Nenner des VIF an und kann daher durch $\frac{1}{VIF}$ ermittelt werden.

```{r label=tbl-viftolerance}
vif_values <- vif_values[1][[1]]
tolerance_values <- 1 / vif_values[1]

vif_table <- data.frame(
  VIF = round(vif_values, 2),
  Toleranz = round(tolerance_values, 2)
)

nice_table(vif_table, title = c("Tabelle 3", "VIF und Toleranz"))
```

##### Vorgehensweisen bei Multikollinearität

Beim Vorliegen von Multikollinearität können wir überlegen, Prädiktoren aus dem Modell zu entfernen oder mehrere Prädiktoren zu einem zusammenzufassen (z.B. Principal Component Analysis, PCA).

## MLR mit diskretem Prädiktor

$$Y_i = \alpha + \beta_{1} \cdot D_{i} + \beta_2 \cdot X_1 + \beta_3 (D_i \cdot X_1) + \epsilon_i$$

Hierfür müssen wir sogenannte Dummy-Variablen ($D_i$) erstellen. Hat der diskrete Prädiktor zwei Ausprägungen, legen wir eine der Kategorien als Referenzkategorie fest. Die Referenzkategorie kann frei gewählt werden, wir müssen uns jedoch für die Interpretation merken, welche Ausprägung wir als Referenz festgelegt haben.

$D_i = 0$: Person $i$ gehört zur Referenzkategorie

$D_i = 1$: Person $i$ gehört nicht zur Referenzkategorie

Für die Referenzkategorie ($D_i = 0$), gilt:

\begin{align}
Y_i &= \alpha + \beta_{1} \cdot 0 + \beta_2 \cdot X_1 + \beta_3 (0 \cdot X_1) + \epsilon_i \\
    &= \alpha + \beta_2 \cdot X_1 + \epsilon_i
\end{align}

\[error: passt nicht zusammen\]

```{r, include=FALSE }
df <- read_csv('.//data_1.csv')
```

```{r}
# Rekodieren zu Dummy Variable
df$experimentalgruppe <- ifelse(
  df$bedingung == "Experimental", 1,
  ifelse(df$bedingung == "Kontroll", 0, NA_real_)
)

```

```{r}
model_dummy_regression <- lm(numerical_ability ~ experimentalgruppe + IQ + experimentalgruppe * IQ , data = df)

summary(model_dummy_regression)
```

```{r label=fig-dummyscatter, warning=FALSE}
# Add predicted values from the model
df$ex_predicted <- predict(model_dummy_regression, newdata = df)

# Plot mit zwei separaten Regressionslinien
ggplot(df, aes(x = IQ, y = numerical_ability, color = factor(experimentalgruppe))) +
  geom_point(alpha = 0.6) +  # Scatter points
  geom_line(data = df, aes(y = ex_predicted), linewidth = 1.2) +  # Regression lines
  scale_color_manual(values = c("blue", "red"), labels = c(0, 1)) +
  labs(x = "IQ", y = "Numerische Fähigkeiten", color = "experimentalgruppe") + 
  theme_classic()



```

## Quadratische Regression

Wenn zwischen Prädiktor und Kriterium ein U-förmiger Zusammenhang besteht, kann es sinnvoll sein, den quadrierten Prädiktor in das Modell aufzunehmen. Idealerweise ist ein solcher Zusammenhang a-priori formuliert und theoretisch begründet. Alternativ kann bei einer Verletzung der Linearitätsannahme auch explorativ geprüft werden, ob ein nicht-linearer Zusammenhang vorliegt. Non-lineare Zusammenhänge in der Stichprobe können auch zufallsbedingt sein. Daher ist es nicht immer sinnvoll, einen explorativ gefundenen non-linearen Zusammenhang als solchen zu interpretieren. Wir können theoretisch auch Prädiktoren höherer Ordnung (bsp. $x_1^3$ oder $x_1^4$) ins Modell mit aufnehmen. In der Psychologie sind solche Zusammenhänge allerdings sehr selten und wir laufen Gefahr zu "overfitten", also unsystematische Varianz als systematisch zu interpretieren.

Die folgende Scatterplot-Matrix zeigt, warum man die Linearität am besten aus beiden Perspektiven – also mit jeweils vertauschter x- und y-Achse – beurteilen sollte. Der U-förmige Zusammenhang zwischen der Leistung (`correct_items`) und dem Vertrauen in die eigene Kompetenz (`confidence`) wird in der Ansicht \[1,3\] mit correct_items auf der x-Achse deutlich klarer als in der Ansicht \[3,1\].

```{r label=fig-ggpairsscatterplotquad, message=FALSE, warning=FALSE, fig.width=7, fig.height=5}
ggpairs(df, columns = c("correct_items", "IQ", "confidence"),
        lower = list(continuous = wrap("smooth", method = "loess", se = TRUE)),
        upper = list(continuous = wrap("smooth", method = "loess", se = TRUE)
        )
)
```

Im statistischen Modell verwenden wir i.d.R. den herkömmlichen Prädiktor ($x_1$) und seine quadratische Variante ($x_1^2$). Die Interpretation des quadratischen Regressionskoeffizienten ist nicht mehr intuitiv: diese geben normalerweise die Steigung an. Im quadratischen Prädiktor hängt die Steigung von der Position auf der x-Achse ab. Wenn $\beta_3 > 0$, ist der non-lineare Zusammenhang U-förmig. Wenn $\beta_3 < 0$, ist der non-lineare Zusammenhang umgekehrt-U-förmig (wie im folgenden Beispiel). Dies ist die selbe Logik wie bei Parabeln in der Mathematik ($y = x^2$ vs. $y = -x^2$)

$$Y_i = \alpha + \beta_1 \cdot x_{i1} +  \beta_2 \cdot x_{i2} + \beta_3  \cdot x_{i1}^2 + \epsilon_i$$

```{r}
model_mlr_squared <- lm(correct_items ~ confidence + IQ + I(confidence^2), data = df)
summary(lm.beta(model_mlr_squared))
```

Auch, wenn sich das $\beta_2$ des Prädiktors $x_1^2$ nicht gut interpretieren lässt, können wir testen, wie sehr es den gesamt-Fit verbessert, also wie viel zusätzliche Varianz im Modell es erklärt. Hierfür vergleichen wir das $R^2$ im Model mit Prädiktor und ohne Prädiktor. Siehe hierarchische Regression.

#### Hierarchische Regression

Wir können Prädiktoren in einer theoriegeleiteten Reihenfolge schrittweise in das Modell aufnehmen, um den zusätzlichen Beitrag eines neuen Prädiktors über die bereits enthaltenen Prädiktoren hinaus zu analysieren. Im folgenden Beispiel interessiert uns, ob der quadratische Term von confidence (also confidence²) den Modellfit signifikant verbessert, nachdem bereits confidence (linear) und IQ berücksichtigt wurden. Das sog. Full Model, also mit confidence², ist eine komplexere Version des Reduced Model.

Reduced Model: $Y_i = \alpha + \beta_1 \cdot x_{i1} + \beta_2 \cdot x_{i2} + \epsilon_i$

Full Model: $Y_i = \alpha + \beta_1 \cdot x_{i1} + \beta_2 \cdot x_{i2} + \beta_3 \cdot x_{i1}^2 + \epsilon_i$

```{r}
model_red <- lm(correct_items ~ confidence + IQ, data = df)
summary(model_red)

model_full <- lm(correct_items ~ confidence + IQ + I(confidence^2), data = df)
summary(model_full)
```

Das $\Delta R^2$ beträgt $0.06$ ($R^2_{Full} - R^2_{Red} = 0.433 - 0.367 = 0.066$). Das bedeutet, dass das Full Model 6.6% mehr Varianz im Kriterium `correct_items` erklärt als das Reduced Model.

Wir verwenden die `anova`-Funktion um zu testen, ob der Fit durch das neue Modell signifikant besser ist. Diese misst mit dem aus der Anova bekannten Omnibus F-Test, ob die Verbesserung im Fit statistisch signifikant ist. Das Reduced Model und Full Model müssen hierfür "nested", also verschachtelt, sein (das Full Model ist eine komplexere Version des Reduced Model).

```{r}
anova(model_red, model_full)
```

Die Hinzunahme des quadratischen Terms von Vertrauen in die eigene Leistung verbessert die Vorhersage der korrekt gelösten Items signifikant über das hinaus, was durch IQ und den linearen Zusammenhang mit Vertrauen erklärt wird, $\Delta R^2 = 0.06, F(1, 96) = 11.22, p = .001$.

# Bootstrapping

Bootstrapping ist eine sogenannte Resampling-Methode. Das bedeutet, dass wir aus der vorliegenden Stichprobe zahlreiche neue Stichproben ziehen – und zwar mit Zurücklegen. Das heißt: Eine Person kann in einer neuen Stichprobe mehrfach oder gar nicht vorkommen.

Für jede dieser neuen Stichproben berechnen wir eine Statistik, zum Beispiel einen Mittelwert oder eine Effektgröße. Dadurch erhalten wir eine Verteilung dieser Statistik über alle resampleten Stichproben hinweg. Diese Verteilung erlaubt es uns, Aussagen über die Präzision der Parameterschätzung zu treffen.

In der Praxis wird häufig ein 95%-Konfidenzintervall für den interessierenden Parameter berechnet.

```{r}
# Define function to compute F-statistic
boot_anova <- function(data, indices) {
  sample_data <- data[indices, ]  # Resample data
  
  anova_result <- aov(wellbeing_t2 ~ therapy_group, data = sample_data)
  
  return(summary(anova_result)[[1]]["therapy", "F value"])  # Extract F-value
}

# Apply bootstrapping with 1000 resamples
boot_result_anova <- boot(df_2_wide, statistic = boot_anova, R = 1000)

# View bootstrapped F-distribution
print(boot_result_anova)

```

# Power Analyse

Die Power beschreibt die Wahrscheinlichkeit, einen Effekt zu finden, wenn es diesen wirklich in der Population gibt. Die Power hängt von den folgenden Parametern ab: - Stichprobengröße `n` - Effektgröße (z.B. Cohen's d) - Signifikanzniveau Alpha

In der Regel wollen wir eine Power von .80 oder .90 erreichen. Das Signifikanzniveau Alpha legen wir fest (i.d.R. 0.05 oder 0.01). Da wir die Daten noch nicht erhoben haben, müssen wir die Effektgröße schätzen. Am besten greifen wir hierfür auf die Literatur zurück.

Für die Power-Analyse in R eignet sich das Package `pwr()`. Um die benötigte Sichprobengröße zu berechnen, legen wir für unser Beispiel die Effektgröße als `d = 0.4`, die gewünschte Power auf `power = 0.8` und das Siginifikanzniveau auf `sig.level = 0.05` fest.

#### Power-Analyse: t-Test über zwei unabhängige Stichproben

```{r}
pwr.t.test(d = 0.4,
           power = 0.8,
           sig.level = 0.05,
           type = "two.sample",
           alternative = "two.sided")
```

#### Power-Analyse: Eine einfaktorielle ANOVA mit balancierten Design

Für die Power-Analyse in ANOVA müssen wir das Effektstärkenmaß $\eta^2$ zu erst umrechnenen, um $f$ zu bestimmen. $f$ ist ein Verhältnis der systematischen zur unsystematischen Varianz (die Standardabweichung der Gruppenmittelwerte in der Population ($\sigma_{\mu}$) geteilt durch die Standardabweichung innerhalb ($\sigma$).

$$f = \frac{\sigma_{\mu}}{\sigma} = \sqrt{\frac{\eta^2}{1 - \eta^2}}$$

Indem wir das geschätzte Eta-Quadrat $\hat \eta^2$ in die Formel einsetzen, können wir f schätzen. Wir gehen hier von einem Between-Subject Faktor mit 3 Stufen aus ($k = 3$).

```{r}
eta_square_estimated <- 0.08
f_estimated <- sqrt(eta_square_estimated/(1-eta_square_estimated))

pwr.anova.test(k = 3,
               f = f_estimated,
               power = 0.9,
               sig.level = 0.05)
```

## Weitere Ressourcen für R

```{r, echo=FALSE}
library(knitr)

ressourcen <- data.frame(
  Thema = c(
    "[R for Data Science](https://r4ds.hadley.nz/)",
    "[Learning Statistics with R](https://learningstatisticswithr.com/book/)",
    "[Data Transformation mit `dplyr`](https://rstudio.github.io/cheatsheets/html/data-transformation.html)",
    "[Data Tidying mit `tidyr`](https://rstudio.github.io/cheatsheets/html/tidyr.html)",
    "[Data Import mit dem tidyverse](https://rstudio.github.io/cheatsheets/html/data-import.html)",
    "[Faktoren mit `forcats`](https://rstudio.github.io/cheatsheets/html/factors.html)"
  ),
  Beschreibung = c(
    "Einführung in Datenanalyse mit dem tidyverse",
    "Statistik-Tutorial für Psychologie-Studierende",
    "Cheatsheet zur Datenmanipulation",
    "Cheatsheet zum Aufräumen von Daten",
    "Cheatsheet zum Einlesen von Daten",
    "Cheatsheet zum Umgang mit kategorialen Variablen"
  )
)

kable(ressourcen, format = "markdown", align = "l", col.names = NA)
```


