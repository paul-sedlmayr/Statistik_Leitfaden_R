)
pairs.panels(df[, c("IQ", "numerical_ability", "WMS4_delayed_recall")], ellipses = F)
model_simple_regression <- lm(IQ ~ WMS4_delayed_recall, data = df)
summary(model_simple_regression)
lm.beta(model_simple_regression)
cor(df$IQ, df$WMS4_delayed_recall)
summary(lm.beta(model_simple_regression))
confint(model_simple_regression)
model_slr_results <- nice_lm(model_simple_regression)
model_slr_results[2] <- "WMS4 delayed recall" # WMS als Prädiktor
model_slr_results
model_slr_results <- nice_table(model_slr_results,
title = c("Tabelle 1", "Zusammenhang von Gedächtnisfähigkeit (verzögerte Wiedergabe) und Intelligenz"),
note = c(paste("Diese Tablle ist als Beispiel gedacht. Alle Zusammenhänge sind frei erfunden.", sep = " "), "* p < .05, ** p < .01, *** p < .001"))
#Um Tabelle als Word-Datei zu speichern
#flextable::save_as_docx(model_slr_results, path = "model_slr_results.docx")
model_slr_results
model_mlr <- lm(IQ ~ numerical_ability + WMS4_delayed_recall + numerical_ability * WMS4_delayed_recall, data = df)
model_mlr_stan <- summary(lm.beta(model_mlr)) # für standardisiertes Regressionsgewicht
model_mlr_stan
model_mlr_table <- tidy(model_mlr_stan)
colnames(model_mlr_table) <- c("Variable", "b", "β", "SE", "t", "p") # "\u03B2" kann statt β verwendet werden
model_mlr_table
confint(model_mlr)
nice_table(model_mlr_table,
title = c("Tabelle 2", "Vorhersage der Intelligenz durch Gedächtnisfähigkeit (verzögerte Wiedergabe) und numerischen Fähigkeiten"),
note = c(
paste("Diese Tablle ist als Beispiel gedacht. Alle Zusammenhänge sind frei erfunden.", sep = " "), "* p < .05, ** p < .01, *** p < .001"))
# Extract standardized residuals and fitted values
residuals <- rstandard(model_mlr)
fitted_values <- fitted(model_mlr)
# Plot residuals against fitted values
plot(jitter(fitted_values), residuals,
xlab = "Fitted Values",
ylab = "Residuals",
main = "Residuals")
abline(h = 0, col = "red")
ggpairs(df, columns = c("IQ", "numerical_ability", "WMS4_delayed_recall"),
lower = list(continuous = wrap("smooth", method = "loess", se = TRUE)),
upper = list(continuous = wrap("smooth", method = "loess", se = TRUE)
)
)
# Wir extrahieren die residuen
residuals_mult_regression <- residuals(model_mlr)
qqnorm(residuals_mult_regression, main = "QQ-Plot")
qqline(residuals_mult_regression)
hist(rstandard(model_mlr))
describe(residuals_mult_regression)$skew
describe(residuals_mult_regression)$kurtosis
durbinWatsonTest(model_mlr)
# Mittelwert und Standardabweichung berechnen
mean_value <- mean(df$Alter)
sd_value <- sd(df$Alter)
# Absoluter Abstand mehr als 3 SD
df$outlier <- abs(df$Alter - mean_value) > (3 * sd_value)
# Optional: Visualize outliers
ggplot(df, aes(x = Alter, y = Offenheit)) +
geom_point(aes(color = outlier), alpha = 0.6) +
scale_color_manual(values = c("black", "red"))
vif_values <- vif(model_mlr, type = "predictor")
vif_values
vif_values <- vif_values[1][[1]]
tolerance_values <- 1 / vif_values[1]
vif_table <- data.frame(
VIF = round(vif_values, 2),
Toleranz = round(tolerance_values, 2)
)
nice_table(vif_table, title = c("Tabelle 3", "VIF und Toleranz"))
df <- read_csv('.//data_1.csv')
# Rekodieren zu Dummy Variable
df$experimentalgruppe <- ifelse(
df$bedingung == "Experimental", 1,
ifelse(df$bedingung == "Kontroll", 0, NA_real_)
)
model_dummy_regression <- lm(Extraversion ~ experimentalgruppe + Neurotizismus + experimentalgruppe * Neurotizismus , data = df)
summary(model_dummy_regression)
# Add predicted values from the model
df$ex_predicted <- predict(model_dummy_regression, newdata = df)
# Plot mit zwei separaten Regressionslinien
ggplot(df, aes(x = Neurotizismus, y = Extraversion, color = factor(experimentalgruppe))) +
geom_point(alpha = 0.6) +  # Scatter points
geom_line(data = df, aes(y = ex_predicted), linewidth = 1.2) +  # Regression lines
scale_color_manual(values = c("blue", "red"), labels = c(0, 1)) +
labs(x = "Neurotizismus", y = "Extraversion", color = "experimentalgruppe") +
theme_minimal()
ggpairs(df, columns = c("correct_items", "IQ", "confidence"),
lower = list(continuous = wrap("smooth", method = "loess", se = TRUE)),
upper = list(continuous = wrap("smooth", method = "loess", se = TRUE)
)
)
model_mlr_squared <- lm(correct_items ~ confidence + IQ + I(confidence^2), data = df)
summary(lm.beta(model_mlr_squared))
model_red <- lm(correct_items ~ confidence + IQ, data = df)
summary(model_red)
model_full <- lm(correct_items ~ confidence + IQ + I(confidence^2), data = df)
summary(model_full)
anova(model_red, model_full)
# Define function to compute F-statistic
boot_anova <- function(data, indices) {
sample_data <- data[indices, ]  # Resample data
anova_result <- aov(wellbeing_t2 ~ therapy_group, data = sample_data)
return(summary(anova_result)[[1]]["therapy", "F value"])  # Extract F-value
}
# Apply bootstrapping with 1000 resamples
boot_result_anova <- boot(df_2_wide, statistic = boot_anova, R = 1000)
# View bootstrapped F-distribution
print(boot_result_anova)
library(knitr)
ressourcen <- data.frame(
Thema = c(
"[R for Data Science](https://r4ds.hadley.nz/)",
"[Learning Statistics with R](https://learningstatisticswithr.com/book/)",
"[Data Transformation mit `dplyr`](https://rstudio.github.io/cheatsheets/html/data-transformation.html)",
"[Data Tidying mit `tidyr`](https://rstudio.github.io/cheatsheets/html/tidyr.html)",
"[Data Import mit dem tidyverse](https://rstudio.github.io/cheatsheets/html/data-import.html)",
"[Faktoren mit `forcats`](https://rstudio.github.io/cheatsheets/html/factors.html)"
),
Beschreibung = c(
"Einführung in Datenanalyse mit dem tidyverse",
"Statistik-Tutorial für Psychologie-Studierende",
"Cheatsheet zur Datenmanipulation",
"Cheatsheet zum Aufräumen von Daten",
"Cheatsheet zum Einlesen von Daten",
"Cheatsheet zum Umgang mit kategorialen Variablen"
)
)
kable(ressourcen, format = "markdown", align = "l", col.names = NA)
table(df_2$therapy_group)
df_2 <- read_csv('.//data_2.csv')
head(df_2)
set.seed(123)  # für Reproduzierbarkeit
# 1. Personen aus der no_therapy-Gruppe
no_therapy_ids <- which(df$therapy == "no_therapy")
# 2. Zufällig 20 davon auswählen
selected_ids <- sample(no_therapy_ids, size = 20)
set.seed(123)  # für Reproduzierbarkeit
# 1. Personen aus der no_therapy-Gruppe
no_therapy_ids <- which(df_2$therapy == "no_therapy")
# 2. Zufällig 20 davon auswählen
selected_ids <- sample(no_therapy_ids, size = 20)
set.seed(123)  # für Reproduzierbarkeit
# 1. Personen aus der no_therapy-Gruppe
no_therapy_ids <- which(df_2$therapy_group == "no_therapy")
# 2. Zufällig 20 davon auswählen
selected_ids <- sample(no_therapy_ids, size = 20)
# 3. Zufällig auf zwei Therapiegruppen aufteilen
new_groups <- sample(c("cognitive-behavioral", "gestalt"), size = 20, replace = TRUE)
# 4. Therapiegruppe in df_2 ändern
df_2$therapy_group[selected_ids] <- new_groups
table(df_3$therapy_group)
table(df_2$therapy_group)
df_2 <- read_csv('.//data_2.csv')
head(df_2)
table(df_2$therapy_group)
set.seed(123)  # für Reproduzierbarkeit
# 1. Personen aus der no_therapy-Gruppe
no_therapy_ids <- which(df_2$therapy_group == "no_therapy")
# 2. Zufällig 20 davon auswählen
selected_ids <- sample(no_therapy_ids, size = 20)
# 3. Zufällig auf zwei Therapiegruppen aufteilen
new_groups <- sample(c("cognitive-behavioral", "gestalt"), size = 20, replace = TRUE)
# 4. Therapiegruppe in df_2 ändern
df_2$therapy_group[selected_ids] <- new_groups
table(df_2$therapy_group)
df_2$wellbeing_t1[df_2$therapy_group == "cognitive-behavioral"] <-
df_2$wellbeing_t1[df_2$therapy_group == "cognitive-behavioral"] + 1
df_2$wellbeing_t2[df_2$therapy_group == "cognitive-behavioral"] <-
df_2$wellbeing_t2[df_2$therapy_group == "cognitive-behavioral"] + 2
df_2$wellbeing_t2[df_2$therapy_group == "gestalt"] <-
df_2$wellbeing_t2[df_2$therapy_group == "gestalt"] + 1
write_csv(df_2, ".//data_2.csv")
knitr::opts_chunk$set(tidy = TRUE, fig.width = 5, fig.height = 3, dev = "png",
cache = TRUE, echo = TRUE, message = FALSE, warning = FALSE)
# Dies ist ein Kommentar
# Packages installieren
#install.packages("tidyverse")
# Diese Funktion müssen wir für alle noch nicht heruntergeladenen Packages anwenden. Weitere Packages im Skript:
# "rempsyc", "haven", "car", "effectsize" ,"psych", "GGally", "afex", "emmeans", "boot"
# Packages laden
library(tidyverse) # All-around package
library(rempsyc) # Convenience-functions für Psychologie
library(haven) # SPSS-Files (.sav) einlesen
library(car) # Anova
library(afex) # Anova
library(emmeans) # Post-hoc Tests
library(effectsize) # Effektstärkten
library(psych) # All-around package für Statistik
library(GGally) # Korrelationsmatrix
library(lm.beta) # Standardiertes Regressionsgewicht
library(flextable) # Tabelle in Word konvertieren
library(broom) # Für schöne lm-Tabelle
library(boot) # Bootstrapping
# Dies ist ein Kommentar
x <- 10 # oder x = 10
x
text_y <- "Hello"
text_z <- "WORLD"
# Print: um ein Objekt zu "drucken"
print(text_y)
text_y_z <- c(text_y, text_z)
text_y_z
# 1. Normal
cars_filtered <- filter(mtcars, mpg > 20)
cars_selected <- select(cars_filtered, mpg, cyl, hp)
cars_final <- arrange(cars_selected, desc(hp))
# 2. Mit Pipe %>%
cars_final <- mtcars %>% filter(mpg > 20) %>% select(mpg, cyl, hp) %>% arrange(desc(hp))
# Die ersten 3 Reihen anzeigen
head(cars_final, 3)
x^2
# Vector erstellen
vec_1 <- c(5, 10, 15)
vec_1
vec_1[1]
vec_1[2]
vec_1[3]
vec_1 * 2
# CSV-Datei einlesen
df <- read_csv('.//data_1.csv')
df$numerical_ability <- -df$Mathematiknote + rnorm(100, mean = 10, sd = 1)
# #.//data_1.csv)
# SAV-Datei einlesen
df_sav <- read_sav(".//data_2.sav")
# Ersten fünf Zeilen
head(df, 5)
colnames(df)
summary(df$IQ)
table(df$bedingung)
# Variable umbenennen nach dem Schema: "neu" = alt
df <- df %>% rename("WMS4_delayed_recall" = wmsva14)
# Variable transformieren: zu einem Faktor, d.h. Nominalskalenniveau
df$Bildungsstand <- df$Bildungsstand %>% as_factor()
# Keine Angabe in Variable "Rauchen" wird zu NA
df$Rauchen[df$Rauchen == "Keine Angabe"] <- NA
# Rekodieren zu Dummy Variable
df$experimentalgruppe <- ifelse(
df$bedingung == "Experimental", 1,
ifelse(df$bedingung == "Kontroll", 0, NA_real_)
)
df <- df %>% mutate(BDI_z2 = ((BDI - mean(BDI)) / sd(BDI)))
df$BDI_c <- df$BDI - mean(df$BDI)
df_2 <- read_csv('.//data_2.csv')
head(df_2)
# Daten ins long-Format bringen: neue Spalte "time" mit Zeitpunkt sowie "wellbeing" mit Zellenwerten der alten Spalten
colnames(df_2) <- as.character(colnames(df_2))
df_2_long <- pivot_longer(data = df_2, cols = c("wellbeing_t0", "wellbeing_t1", "wellbeing_t2"), names_to = "time", values_to = "wellbeing")
head(df_2_long)
df_2_wide <- pivot_wider(data = df_2_long, names_from = "time", values_from = "wellbeing", id_cols = c("participant_id", "therapy", "therapy_group", "gender"))
head(df_2_wide)
mean(df$Gewissenhaftigkeit)
sd(df$Gewissenhaftigkeit)
descriptives <- df %>%
group_by(bedingung) %>%
summarize(
M = mean(Gewissenhaftigkeit),
SD = sd(Gewissenhaftigkeit),
n = n(),
)
descriptives
describe(df$Extraversion)
t.test(df$IQ, mu = 100)
t.test(Gewissenhaftigkeit ~ bedingung, data = df, var.equal = FALSE)
t.test(df_2$wellbeing_t0 , df_2$wellbeing_t1, paired = TRUE)
df_bedingung <- df %>% filter(!is.na(bedingung))
ggplot(data = df_bedingung, mapping = aes(x = Gewissenhaftigkeit)) +
geom_histogram(bins = 20, color = "black", fill = "steelblue") +
facet_wrap(~ bedingung) +
labs(title = "Histogram", y = "Häufigkeit")
nice_qq(df_bedingung, variable = "Gewissenhaftigkeit", group = "bedingung", title = NULL)
leveneTest(Gewissenhaftigkeit ~ bedingung, data = df)
# ID Spalte pro Participant hinzufügen
df_2_wide$participant_id <- c(1:length(df_2_wide$wellbeing_t2))
# Between-UV's als Faktor konvertieren
df_2_wide$therapy_group <- df_2_wide$therapy_group %>% as_factor()
df_2_wide$gender <- df_2_wide$gender %>% as_factor()
df_2_wide$therapy <- df_2_wide$therapy %>% as_factor()
df_2_long$gender <- df_2_long$gender %>% as_factor()
df_2_long$therapy <- df_2_long$therapy %>% as_factor()
anova_bet <- aov_ez(id = "participant_id", dv = "wellbeing_t2", between = "therapy_group", data = df_2_wide, anova_table = list(es = "pes"))
anova_bet
# Alternativ mit aov()
#aov(wellbeing ~ therapy, data = df_2_long)
anova_within <- aov_ez(id = "participant_id", dv = "wellbeing", within = "time", anova_table = list(es = "pes"), data = df_2_long)
anova_within
ggplot(df_2_long, aes(x = time, y = wellbeing, fill = time)) +
geom_boxplot(alpha = 0.6, outlier.color = "red", outlier.shape = 16) +
labs(title = "Well-being über Zeit",
x = "Zeitpunkt",
y = "Well-being Score") +
theme_minimal() +
theme(legend.position = "none")  # Remove legend
anova_2_bet <- aov_ez(id = "participant_id", dv = "wellbeing_t2", between = c("therapy_group", "gender"), data = df_2_wide, anova_table = list(es = "pes"))
anova_2_bet
# Alternativ mit aov()
#anova_result <- aov(Wor ~ gender * S_E, data = df_2_wide)
interaction.plot(df_2_wide$therapy_group, df_2_wide$gender, df_2_wide$wellbeing_t2, col = c("blue", "red"),
lty = 1, lwd = 2, legend = TRUE, xlab = "Art der Therapie", ylab = "Well-being zu Zeitpunkt 2", trace.label = "")
anova_mixed <- aov_ez(id = "participant_id", dv = "wellbeing", within = "time", between = "therapy_group", data = df_2_long, anova_table = list(es = "pes"), include_aov = TRUE)
summary(anova_mixed)
interaction.plot(df_2_long$time, df_2_long$therapy_group, df_2_long$wellbeing, col = c("purple", "orange", "green"),
legend = TRUE, lwd = 2, xlab = "Zeit", ylab = "Well-being", trace.label = "Therapie" )
ggplot(df_2_long, aes(x = time, y = wellbeing, color = therapy_group, group = therapy_group)) +
stat_summary(fun = mean, geom = "point", size = 2) +
stat_summary(fun = mean, geom = "line") +
stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2) +
labs(title = "Well-Being über Zeit in Abhängigkeit von der Therapie ",
x = "Zeit",
y = "Well-Being")
effectsize::eta_squared(anova_mixed)
omega_squared(anova_mixed)
# One Between ANOVA
anova_bet <- aov_ez(id = "participant_id", dv = "wellbeing_t2", between = "therapy_group", data = df_2_wide, anova_table = list(es = "pes"))
# Estimated marginal means
estimated_marginal_means <- emmeans(anova_bet, ~ therapy_group)
estimated_marginal_means
levels(df_2_wide$therapy_group)
# Kontrast festlegen
contrast_custom <- contrast(estimated_marginal_means, method = list("CBT_vs_Gestalt_t2" = c(0, 1, -1)))
summary(contrast_custom)
set.seed(100) # for reproducability
nice_contrasts(data = df_2_wide, response = "wellbeing_t2", group = "therapy_group", effect.type = "cohens.d", bootstraps = 1000)
anova_bet <- aov_ez(id = "participant_id", dv = "wellbeing_t2", between = "therapy_group", data = df_2_wide, anova_table = list(es = "pes"))
contrast_matrix <- contrast(estimated_marginal_means,
method = list("Waiting_list_vs_Therapy" = c(1, -0.5, -0.5)))
summary(contrast_matrix)
# Bonfferoni
anova_mixed <- aov_ez(id = "participant_id", dv = "wellbeing", within = "time", between = "therapy_group",
data = df_2_long, anova_table = list(es = "pes"), include_aov = TRUE)
emm_mixed <- emmeans(anova_mixed, ~ therapy_group * time)
as.data.frame(emm_mixed) # Reihenfolge der Kontraste überprüfen
anova_mixed_contrasts <- contrast(
emm_mixed,
method = list(
"CBT_vs_Gestalt_t2" = c(0, 0, 0, 0, 0, 0, 1, -1, 0),
"Waiting_list_vs_Therapy_t2" = c(0, 0, 0, 0, 0, 0, 0.5, 0.5, - 1) ),
adjust = "bonferroni"
)
summary(anova_mixed_contrasts)
emm_only_t2 <- emmeans(anova_mixed, ~ therapy_group, at = list(time = "wellbeing_t2"))
pairs(emm_only_t2, adjust = "tukey")
aov_2_bet <- aov(wellbeing_t2 ~ therapy_group + gender, data = df_2_wide)
posthoc_tukey_2 <- TukeyHSD(aov_2_bet)
plot(posthoc_tukey_2, las = 1)
# Scheffe Post-Hoc Test
pairwise_scheffe <- emmeans(aov_2_bet, pairwise ~ therapy_group + gender, adjust = "scheffe")
pairwise_scheffe
anova_2_bet <- aov_ez(id = "participant_id", dv = "wellbeing_t2", between = c("therapy_group", "gender"), data = df_2_wide, anova_table = list(es = "pes"))
# Extract residuals and fitted values
residuals <- residuals(anova_2_bet)
fitted_values <- fitted(anova_2_bet)
# Plot residuals against fitted values
plot(jitter(fitted_values), residuals,
xlab = "Fitted Values",
ylab = "Residuals",
main = "Residuals of Sub-Groups")
abline(h = 0, col = "red")
leveneTest(wellbeing_t2 ~ therapy_group*gender, data = df_2_wide)
anova_within <- aov_ez(id = "participant_id", dv = "wellbeing", within = "time", anova_table = list(es = "pes"), data = df_2_long)
summary(anova_within)
anova_within
ggplot(data = df_2_wide, mapping = aes(x = wellbeing_t2)) +
geom_histogram(bins = 20, color = "black", fill = "steelblue") +
facet_wrap(~ therapy_group) +
labs(title = "Histogram", y = "Häufigkeit")
# Wir haben die Residuen zuvor extrahiert: residuals <- residuals(anova_result)
df_2_wide$residual <- residuals
qqnorm(df_2_wide$residual, main = "QQ-Plot")
qqline(df_2_wide$residual)
nice_qq(df_2_wide, variable = "residual", title = NULL)
shapiro.test(residuals)
cor(df$numerical_ability, df$Statistiknote, use = "complete.obs")
cor.test(df$Extraversion, df$Neurotizismus)
cor_ex_neu <- cor.test(df$Extraversion, df$Neurotizismus, use = "complete.obs", method = "pearson")
r_value <- cor_ex_neu$estimate  # Pearson-Korrelation (r)
p_value <- cor_ex_neu$p.value    # p-value
ci_lower <- cor_ex_neu$conf.int[1]  # Untere Grenze des 95% KI
ci_upper <- cor_ex_neu$conf.int[2]  # Obere Grenze des 95% KI
cor.test(df$numerical_ability, df$Statistiknote, method = "spearman")
cor.test(df$numerical_ability, df$Statistiknote, method = "kendall")
cor(df[, c("IQ", "numerical_ability", "WMS4_delayed_recall")], method = "pearson", use = "pairwise.complete.obs")
ggpairs(df, columns = c("IQ", "numerical_ability", "WMS4_delayed_recall"),
lower = list(continuous = wrap("smooth", method = "loess", se = TRUE)),
upper = list(continuous = wrap("cor")
)
)
pairs.panels(df[, c("IQ", "numerical_ability", "WMS4_delayed_recall")], ellipses = F)
model_simple_regression <- lm(IQ ~ WMS4_delayed_recall, data = df)
summary(model_simple_regression)
lm.beta(model_simple_regression)
cor(df$IQ, df$WMS4_delayed_recall)
summary(lm.beta(model_simple_regression))
confint(model_simple_regression)
model_slr_results <- nice_lm(model_simple_regression)
model_slr_results[2] <- "WMS4 delayed recall" # WMS als Prädiktor
model_slr_results
model_slr_results <- nice_table(model_slr_results,
title = c("Tabelle 1", "Zusammenhang von Gedächtnisfähigkeit (verzögerte Wiedergabe) und Intelligenz"),
note = c(paste("Diese Tablle ist als Beispiel gedacht. Alle Zusammenhänge sind frei erfunden.", sep = " "), "* p < .05, ** p < .01, *** p < .001"))
#Um Tabelle als Word-Datei zu speichern
#flextable::save_as_docx(model_slr_results, path = "model_slr_results.docx")
model_slr_results
model_mlr <- lm(IQ ~ numerical_ability + WMS4_delayed_recall + numerical_ability * WMS4_delayed_recall, data = df)
model_mlr_stan <- summary(lm.beta(model_mlr)) # für standardisiertes Regressionsgewicht
model_mlr_stan
model_mlr_table <- tidy(model_mlr_stan)
colnames(model_mlr_table) <- c("Variable", "b", "β", "SE", "t", "p") # "\u03B2" kann statt β verwendet werden
model_mlr_table
confint(model_mlr)
nice_table(model_mlr_table,
title = c("Tabelle 2", "Vorhersage der Intelligenz durch Gedächtnisfähigkeit (verzögerte Wiedergabe) und numerischen Fähigkeiten"),
note = c(
paste("Diese Tablle ist als Beispiel gedacht. Alle Zusammenhänge sind frei erfunden.", sep = " "), "* p < .05, ** p < .01, *** p < .001"))
# Extract standardized residuals and fitted values
residuals <- rstandard(model_mlr)
fitted_values <- fitted(model_mlr)
# Plot residuals against fitted values
plot(jitter(fitted_values), residuals,
xlab = "Fitted Values",
ylab = "Residuals",
main = "Residuals")
abline(h = 0, col = "red")
ggpairs(df, columns = c("IQ", "numerical_ability", "WMS4_delayed_recall"),
lower = list(continuous = wrap("smooth", method = "loess", se = TRUE)),
upper = list(continuous = wrap("smooth", method = "loess", se = TRUE)
)
)
# Wir extrahieren die residuen
residuals_mult_regression <- residuals(model_mlr)
qqnorm(residuals_mult_regression, main = "QQ-Plot")
qqline(residuals_mult_regression)
hist(rstandard(model_mlr))
describe(residuals_mult_regression)$skew
describe(residuals_mult_regression)$kurtosis
durbinWatsonTest(model_mlr)
# Mittelwert und Standardabweichung berechnen
mean_value <- mean(df$Alter)
sd_value <- sd(df$Alter)
# Absoluter Abstand mehr als 3 SD
df$outlier <- abs(df$Alter - mean_value) > (3 * sd_value)
# Optional: Visualize outliers
ggplot(df, aes(x = Alter, y = Offenheit)) +
geom_point(aes(color = outlier), alpha = 0.6) +
scale_color_manual(values = c("black", "red"))
vif_values <- vif(model_mlr, type = "predictor")
vif_values
vif_values <- vif_values[1][[1]]
tolerance_values <- 1 / vif_values[1]
vif_table <- data.frame(
VIF = round(vif_values, 2),
Toleranz = round(tolerance_values, 2)
)
nice_table(vif_table, title = c("Tabelle 3", "VIF und Toleranz"))
df <- read_csv('.//data_1.csv')
# Rekodieren zu Dummy Variable
df$experimentalgruppe <- ifelse(
df$bedingung == "Experimental", 1,
ifelse(df$bedingung == "Kontroll", 0, NA_real_)
)
model_dummy_regression <- lm(Extraversion ~ experimentalgruppe + Neurotizismus + experimentalgruppe * Neurotizismus , data = df)
summary(model_dummy_regression)
# Add predicted values from the model
df$ex_predicted <- predict(model_dummy_regression, newdata = df)
# Plot mit zwei separaten Regressionslinien
ggplot(df, aes(x = Neurotizismus, y = Extraversion, color = factor(experimentalgruppe))) +
geom_point(alpha = 0.6) +  # Scatter points
geom_line(data = df, aes(y = ex_predicted), linewidth = 1.2) +  # Regression lines
scale_color_manual(values = c("blue", "red"), labels = c(0, 1)) +
labs(x = "Neurotizismus", y = "Extraversion", color = "experimentalgruppe") +
theme_minimal()
ggpairs(df, columns = c("correct_items", "IQ", "confidence"),
lower = list(continuous = wrap("smooth", method = "loess", se = TRUE)),
upper = list(continuous = wrap("smooth", method = "loess", se = TRUE)
)
)
model_mlr_squared <- lm(correct_items ~ confidence + IQ + I(confidence^2), data = df)
summary(lm.beta(model_mlr_squared))
model_red <- lm(correct_items ~ confidence + IQ, data = df)
summary(model_red)
model_full <- lm(correct_items ~ confidence + IQ + I(confidence^2), data = df)
summary(model_full)
anova(model_red, model_full)
# Define function to compute F-statistic
boot_anova <- function(data, indices) {
sample_data <- data[indices, ]  # Resample data
anova_result <- aov(wellbeing_t2 ~ therapy_group, data = sample_data)
return(summary(anova_result)[[1]]["therapy", "F value"])  # Extract F-value
}
# Apply bootstrapping with 1000 resamples
boot_result_anova <- boot(df_2_wide, statistic = boot_anova, R = 1000)
# View bootstrapped F-distribution
print(boot_result_anova)
library(knitr)
ressourcen <- data.frame(
Thema = c(
"[R for Data Science](https://r4ds.hadley.nz/)",
"[Learning Statistics with R](https://learningstatisticswithr.com/book/)",
"[Data Transformation mit `dplyr`](https://rstudio.github.io/cheatsheets/html/data-transformation.html)",
"[Data Tidying mit `tidyr`](https://rstudio.github.io/cheatsheets/html/tidyr.html)",
"[Data Import mit dem tidyverse](https://rstudio.github.io/cheatsheets/html/data-import.html)",
"[Faktoren mit `forcats`](https://rstudio.github.io/cheatsheets/html/factors.html)"
),
Beschreibung = c(
"Einführung in Datenanalyse mit dem tidyverse",
"Statistik-Tutorial für Psychologie-Studierende",
"Cheatsheet zur Datenmanipulation",
"Cheatsheet zum Aufräumen von Daten",
"Cheatsheet zum Einlesen von Daten",
"Cheatsheet zum Umgang mit kategorialen Variablen"
)
)
kable(ressourcen, format = "markdown", align = "l", col.names = NA)
getwd()
